{"file_contents":{"soil_classification.py":{"content":"import numpy as np\nimport pandas as pd\nfrom typing import List, Dict, Tuple, Optional\n\nclass SoilLayering:\n    \"\"\"\n    Automated soil layering based on Ic transitions and soil behavior type changes.\n    \"\"\"\n    \n    def __init__(self, min_layer_thickness: float = 0.5):\n        \"\"\"\n        Parameters:\n        - min_layer_thickness: Minimum layer thickness in meters (default 0.5m)\n        \"\"\"\n        self.min_layer_thickness = min_layer_thickness\n    \n    def identify_layers(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Identify soil layers based on Ic value transitions.\n        \n        Uses a moving window approach to detect significant changes in soil behavior.\n        \"\"\"\n        if len(df) == 0:\n            return pd.DataFrame()\n        \n        layers = []\n        current_layer_start = 0\n        current_layer_Ic = df['Ic'].iloc[0]\n        current_layer_soil_type = df['soil_type'].iloc[0]\n        \n        # Define Ic thresholds for layer boundaries\n        Ic_threshold = 0.3  # Change of 0.3 in Ic suggests different material\n        \n        for i in range(1, len(df)):\n            Ic_change = abs(df['Ic'].iloc[i] - current_layer_Ic)\n            depth_diff = df['depth'].iloc[i] - df['depth'].iloc[current_layer_start]\n            \n            # Check if we should create a new layer\n            if Ic_change > Ic_threshold and depth_diff >= self.min_layer_thickness:\n                # Store current layer\n                layer = self._create_layer(df, current_layer_start, i)\n                layers.append(layer)\n                \n                # Start new layer\n                current_layer_start = i\n                current_layer_Ic = df['Ic'].iloc[i]\n                current_layer_soil_type = df['soil_type'].iloc[i]\n        \n        # Add the last layer\n        layer = self._create_layer(df, current_layer_start, len(df))\n        layers.append(layer)\n        \n        return pd.DataFrame(layers)\n    \n    def _create_layer(self, df: pd.DataFrame, start_idx: int, end_idx: int) -> Dict:\n        \"\"\"\n        Create a layer dictionary from a DataFrame slice.\n        \"\"\"\n        layer_data = df.iloc[start_idx:end_idx]\n        \n        return {\n            'layer_number': None,  # Will be assigned later\n            'top_depth': layer_data['depth'].iloc[0],\n            'bottom_depth': layer_data['depth'].iloc[-1],\n            'thickness': layer_data['depth'].iloc[-1] - layer_data['depth'].iloc[0],\n            'avg_qc': layer_data['qc'].mean(),\n            'avg_qt': layer_data['qt'].mean(),\n            'avg_fs': layer_data['fs'].mean(),\n            'avg_Ic': layer_data['Ic'].mean(),\n            'avg_Qt': layer_data['Qt1'].mean(),\n            'avg_Fr': layer_data['Fr'].mean(),\n            'avg_Rf': layer_data['Rf'].mean(),\n            'soil_type': layer_data['soil_type'].mode()[0] if len(layer_data) > 0 else \"Unknown\",\n            'avg_sigma_vo_prime': layer_data['sigma_vo_prime'].mean()\n        }\n    \n    def merge_thin_layers(self, layers_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Merge layers thinner than minimum thickness with adjacent layers.\n        \"\"\"\n        if len(layers_df) == 0:\n            return layers_df\n        \n        merged = []\n        i = 0\n        \n        while i < len(layers_df):\n            current = layers_df.iloc[i].to_dict()\n            \n            # Check if layer is too thin\n            if current['thickness'] < self.min_layer_thickness and i < len(layers_df) - 1:\n                # Merge with next layer\n                next_layer = layers_df.iloc[i + 1].to_dict()\n                merged_layer = self._merge_two_layers(current, next_layer)\n                merged.append(merged_layer)\n                i += 2  # Skip the next layer as it's been merged\n            else:\n                merged.append(current)\n                i += 1\n        \n        result = pd.DataFrame(merged)\n        \n        # Renumber layers\n        if len(result) > 0:\n            result['layer_number'] = range(1, len(result) + 1)\n        \n        return result\n    \n    def _merge_two_layers(self, layer1: Dict, layer2: Dict) -> Dict:\n        \"\"\"\n        Merge two adjacent layers by weighted averaging.\n        \"\"\"\n        total_thickness = layer1['thickness'] + layer2['thickness']\n        w1 = layer1['thickness'] / total_thickness\n        w2 = layer2['thickness'] / total_thickness\n        \n        return {\n            'layer_number': layer1['layer_number'],\n            'top_depth': layer1['top_depth'],\n            'bottom_depth': layer2['bottom_depth'],\n            'thickness': total_thickness,\n            'avg_qc': w1 * layer1['avg_qc'] + w2 * layer2['avg_qc'],\n            'avg_qt': w1 * layer1['avg_qt'] + w2 * layer2['avg_qt'],\n            'avg_fs': w1 * layer1['avg_fs'] + w2 * layer2['avg_fs'],\n            'avg_Ic': w1 * layer1['avg_Ic'] + w2 * layer2['avg_Ic'],\n            'avg_Qt': w1 * layer1['avg_Qt'] + w2 * layer2['avg_Qt'],\n            'avg_Fr': w1 * layer1['avg_Fr'] + w2 * layer2['avg_Fr'],\n            'avg_Rf': w1 * layer1['avg_Rf'] + w2 * layer2['avg_Rf'],\n            'soil_type': layer1['soil_type'],  # Use first layer's type\n            'avg_sigma_vo_prime': w1 * layer1['avg_sigma_vo_prime'] + w2 * layer2['avg_sigma_vo_prime']\n        }\n    \n    def process_layering(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Complete layering process: identify, merge thin layers, and number.\n        \"\"\"\n        layers = self.identify_layers(df)\n        layers = self.merge_thin_layers(layers)\n        \n        if len(layers) > 0:\n            layers['layer_number'] = range(1, len(layers) + 1)\n        \n        return layers\n\n\nclass RobertsonClassification:\n    \"\"\"\n    Robertson (2009) soil classification chart implementation.\n    \"\"\"\n    \n    @staticmethod\n    def get_classification_zones() -> Dict[int, Dict]:\n        \"\"\"\n        Returns the Robertson (2009) soil behavior type zone definitions.\n        \"\"\"\n        return {\n            1: {\n                'name': 'Sensitive, fine grained',\n                'Ic_range': (3.60, 4.0),\n                'color': '#8B4513'\n            },\n            2: {\n                'name': 'Organic soils - clay',\n                'Ic_range': (3.60, 4.0),\n                'color': '#654321'\n            },\n            3: {\n                'name': 'Clays: silty clay to clay',\n                'Ic_range': (2.95, 3.60),\n                'color': '#A0522D'\n            },\n            4: {\n                'name': 'Silt mixtures: clayey silt to silty clay',\n                'Ic_range': (2.60, 2.95),\n                'color': '#CD853F'\n            },\n            5: {\n                'name': 'Sand mixtures: silty sand to sandy silt',\n                'Ic_range': (2.05, 2.60),\n                'color': '#DEB887'\n            },\n            6: {\n                'name': 'Sands: clean sand to silty sand',\n                'Ic_range': (1.31, 2.05),\n                'color': '#F4A460'\n            },\n            7: {\n                'name': 'Gravelly sand to dense sand',\n                'Ic_range': (0.0, 1.31),\n                'color': '#FFD700'\n            }\n        }\n    \n    @staticmethod\n    def get_zone_from_Ic(Ic: float) -> int:\n        \"\"\"\n        Get Robertson zone number from Ic value.\n        \"\"\"\n        if Ic >= 3.60:\n            return 3 if Ic < 4.0 else 2\n        elif Ic >= 2.95:\n            return 3\n        elif Ic >= 2.60:\n            return 4\n        elif Ic >= 2.05:\n            return 5\n        elif Ic >= 1.31:\n            return 6\n        else:\n            return 7\n    \n    @staticmethod\n    def calculate_Ic_contours(Qt_range: Tuple[float, float], \n                              num_points: int = 100) -> Dict[float, np.ndarray]:\n        \"\"\"\n        Calculate Ic contour lines for plotting on Qt-Fr chart.\n        \n        Ic = sqrt((3.47 - log10(Qt))^2 + (log10(Fr) + 1.22)^2)\n        \"\"\"\n        Ic_values = [1.31, 2.05, 2.60, 2.95, 3.60]\n        contours = {}\n        \n        Qt_array = np.logspace(np.log10(Qt_range[0]), np.log10(Qt_range[1]), num_points)\n        \n        for Ic in Ic_values:\n            # Solve for Fr from Ic equation\n            # Fr = 10^(sqrt(Ic^2 - (3.47 - log10(Qt))^2) - 1.22)\n            log_Qt = np.log10(Qt_array)\n            discriminant = Ic**2 - (3.47 - log_Qt)**2\n            \n            # Only calculate where discriminant is positive\n            valid_idx = discriminant >= 0\n            Fr_array = np.full_like(Qt_array, np.nan)\n            Fr_array[valid_idx] = 10**(np.sqrt(discriminant[valid_idx]) - 1.22)\n            \n            contours[Ic] = np.column_stack([Qt_array, Fr_array])\n        \n        return contours\n\n\nclass Robertson1990Classification:\n    \"\"\"\n    Robertson (1990) normalized CPT soil classification chart implementation.\n    Uses stress-normalized parameters and 9 soil behavior type zones.\n    \"\"\"\n    \n    @staticmethod\n    def get_classification_zones() -> Dict[int, Dict]:\n        \"\"\"\n        Returns the Robertson (1990) soil behavior type zone definitions.\n        \"\"\"\n        return {\n            1: {\n                'name': 'Sensitive fine-grained',\n                'Ic_range': (3.60, 5.0),\n                'color': '#8B4513'\n            },\n            2: {\n                'name': 'Clay - organic soil',\n                'Ic_range': (2.95, 3.60),\n                'color': '#654321'\n            },\n            3: {\n                'name': 'Clay to silty clay',\n                'Ic_range': (2.60, 2.95),\n                'color': '#A0522D'\n            },\n            4: {\n                'name': 'Silt mixtures - clayey silt to silty clay',\n                'Ic_range': (2.05, 2.60),\n                'color': '#CD853F'\n            },\n            5: {\n                'name': 'Sand mixtures - silty sand to sandy silt',\n                'Ic_range': (1.31, 2.05),\n                'color': '#DEB887'\n            },\n            6: {\n                'name': 'Sands - clean sand to silty sand',\n                'Ic_range': (0.0, 1.31),\n                'color': '#F4A460'\n            },\n            7: {\n                'name': 'Dense sand to gravelly sand',\n                'Ic_range': (0.0, 1.31),\n                'color': '#FFD700',\n                'Qt_threshold': 100\n            },\n            8: {\n                'name': 'Stiff sand to clayey sand',\n                'Ic_range': (1.31, 2.05),\n                'color': '#FFA500',\n                'overconsolidated': True\n            },\n            9: {\n                'name': 'Stiff fine-grained',\n                'Ic_range': (2.05, 5.0),\n                'color': '#FF8C00',\n                'overconsolidated': True\n            }\n        }\n    \n    @staticmethod\n    def classify_soil_type(Qt: float, Fr: float, Ic: float) -> str:\n        \"\"\"\n        Classify soil type based on Robertson 1990 normalized parameters.\n        \"\"\"\n        if Ic >= 3.60:\n            return 'Sensitive fine-grained'\n        elif Ic >= 2.95:\n            return 'Clay - organic soil'\n        elif Ic >= 2.60:\n            return 'Clay to silty clay'\n        elif Ic >= 2.05:\n            if Qt > 50:  # Overconsolidated\n                return 'Stiff fine-grained'\n            else:\n                return 'Silt mixtures - clayey silt to silty clay'\n        elif Ic >= 1.31:\n            if Qt > 50:  # Dense or overconsolidated\n                return 'Stiff sand to clayey sand'\n            else:\n                return 'Sand mixtures - silty sand to sandy silt'\n        else:\n            if Qt > 100:\n                return 'Dense sand to gravelly sand'\n            else:\n                return 'Sands - clean sand to silty sand'\n    \n    @staticmethod\n    def calculate_Ic_contours(Qt_range: Tuple[float, float], \n                              num_points: int = 100) -> Dict[float, np.ndarray]:\n        \"\"\"\n        Calculate Ic contour lines for Robertson 1990 classification.\n        Same formula as Robertson 2009.\n        \"\"\"\n        Ic_values = [1.31, 2.05, 2.60, 2.95, 3.60]\n        contours = {}\n        \n        Qt_array = np.logspace(np.log10(Qt_range[0]), np.log10(Qt_range[1]), num_points)\n        \n        for Ic in Ic_values:\n            log_Qt = np.log10(Qt_array)\n            discriminant = Ic**2 - (3.47 - log_Qt)**2\n            \n            valid_idx = discriminant >= 0\n            Fr_array = np.full_like(Qt_array, np.nan)\n            Fr_array[valid_idx] = 10**(np.sqrt(discriminant[valid_idx]) - 1.22)\n            \n            contours[Ic] = np.column_stack([Qt_array, Fr_array])\n        \n        return contours\n\n\nclass Schneider2008Classification:\n    \"\"\"\n    Schneider et al. (2008) CPTu soil classification chart implementation.\n    Focuses on drainage conditions and uses Q-F and Q-Bq charts.\n    \"\"\"\n    \n    @staticmethod\n    def get_classification_zones() -> Dict[str, Dict]:\n        \"\"\"\n        Returns the Schneider (2008) soil behavior type zone definitions.\n        \"\"\"\n        return {\n            '1a': {\n                'name': 'Clays - high friction',\n                'description': 'Claylike soils with higher friction ratios',\n                'color': '#8B4513',\n                'F_min': 2.0\n            },\n            '1b': {\n                'name': 'Clays - standard',\n                'description': 'Standard claylike soils',\n                'color': '#A0522D',\n                'F_range': (1.0, 2.0)\n            },\n            '1c': {\n                'name': 'Sensitive and cemented clays',\n                'description': 'Sensitive, structured or cemented clays',\n                'color': '#654321',\n                'F_max': 1.0\n            },\n            '2': {\n                'name': 'Drained sands',\n                'description': 'Essentially drained sands and gravels',\n                'color': '#FFD700',\n                'Q_min': 20,\n                'drainage': 'drained'\n            },\n            '3': {\n                'name': 'Transitional soils',\n                'description': 'Partially drained transitional soils (silts)',\n                'color': '#DEB887',\n                'drainage': 'partial'\n            }\n        }\n    \n    @staticmethod\n    def classify_soil_type(Q: float, F: float, Bq: Optional[float] = None) -> str:\n        \"\"\"\n        Classify soil type based on Schneider 2008 parameters.\n        \n        Parameters:\n        -----------\n        Q : float\n            Normalized cone resistance Q = (qt - Ïƒvo) / Ïƒ'vo\n        F : float\n            Friction ratio F = fs / (qt - Ïƒvo) Ã— 100\n        Bq : float, optional\n            Pore pressure ratio (for refined classification)\n        \"\"\"\n        # Zone 2: Drained sands\n        if Q > 20 and F < 2.0:\n            return 'Drained sands'\n        \n        # Zone 3: Transitional soils\n        elif Q > 10 and F < 4.0:\n            return 'Transitional soils'\n        \n        # Zone 1: Claylike soils\n        elif Q < 20:\n            if F >= 2.0:\n                return 'Clays - high friction'\n            elif F >= 1.0:\n                return 'Clays - standard'\n            else:\n                return 'Sensitive and cemented clays'\n        \n        # Default to transitional\n        else:\n            return 'Transitional soils'\n    \n    @staticmethod\n    def calculate_zone_boundaries() -> Dict[str, np.ndarray]:\n        \"\"\"\n        Calculate zone boundary lines for Schneider 2008 Q-F chart.\n        \"\"\"\n        boundaries = {}\n        \n        # Q range for plotting\n        Q_array = np.logspace(0, 3, 100)  # 1 to 1000\n        \n        # Boundary between zones 1 and 2/3 (Q = 20)\n        boundaries['sand_boundary'] = np.array([[20, 0.1], [20, 10]])\n        \n        # Boundary between zones 2 and 3 (Q = 10, F = 2)\n        boundaries['transitional_boundary'] = np.array([[10, 0.1], [10, 4]])\n        \n        # Zone 1 subdivisions based on F values\n        boundaries['zone_1a_1b'] = np.array([[0.1, 2.0], [20, 2.0]])\n        boundaries['zone_1b_1c'] = np.array([[0.1, 1.0], [20, 1.0]])\n        \n        return boundaries\n\n\nclass ClassificationComparator:\n    \"\"\"\n    Compare results from different CPT classification methods.\n    \"\"\"\n    \n    @staticmethod\n    def compare_classifications(data: pd.DataFrame, method1: str = 'Robertson2009', \n                               method2: str = 'Robertson1990') -> pd.DataFrame:\n        \"\"\"\n        Compare soil classifications from two different methods.\n        \n        Returns a DataFrame with both classifications and agreement statistics.\n        \"\"\"\n        comparison = data.copy()\n        \n        if method1 == 'Robertson2009':\n            comparison['method1_soil_type'] = data['soil_type']\n        elif method1 == 'Robertson1990':\n            comparison['method1_soil_type'] = data.apply(\n                lambda row: Robertson1990Classification.classify_soil_type(\n                    row['Qt1'], row['Fr'], row['Ic']\n                ), axis=1\n            )\n        elif method1 == 'Schneider2008':\n            comparison['method1_soil_type'] = data.apply(\n                lambda row: Schneider2008Classification.classify_soil_type(\n                    row['Qt1'], row['Fr']\n                ), axis=1\n            )\n        \n        if method2 == 'Robertson2009':\n            comparison['method2_soil_type'] = data['soil_type']\n        elif method2 == 'Robertson1990':\n            comparison['method2_soil_type'] = data.apply(\n                lambda row: Robertson1990Classification.classify_soil_type(\n                    row['Qt1'], row['Fr'], row['Ic']\n                ), axis=1\n            )\n        elif method2 == 'Schneider2008':\n            comparison['method2_soil_type'] = data.apply(\n                lambda row: Schneider2008Classification.classify_soil_type(\n                    row['Qt1'], row['Fr']\n                ), axis=1\n            )\n        \n        # Calculate agreement\n        comparison['agreement'] = comparison['method1_soil_type'] == comparison['method2_soil_type']\n        \n        return comparison\n    \n    @staticmethod\n    def get_agreement_statistics(comparison: pd.DataFrame) -> Dict:\n        \"\"\"\n        Calculate statistics on classification agreement.\n        \"\"\"\n        total = len(comparison)\n        agreed = comparison['agreement'].sum()\n        \n        return {\n            'total_points': total,\n            'agreed_points': agreed,\n            'disagreed_points': total - agreed,\n            'agreement_percentage': (agreed / total * 100) if total > 0 else 0\n        }\n","size_bytes":18370},"main.py":{"content":"def main():\n    print(\"Hello from repl-nix-workspace!\")\n\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":96},"sample_cpt_data.py":{"content":"import pandas as pd\nimport numpy as np\n\ndef create_sample_cpt_data():\n    \"\"\"\n    Create sample CPT data for testing the application.\n    Simulates a typical soil profile with sandy and clayey layers.\n    \"\"\"\n    \n    np.random.seed(42)\n    \n    depths = np.arange(0, 20.5, 0.5)\n    n_points = len(depths)\n    \n    qc = np.zeros(n_points)\n    fs = np.zeros(n_points)\n    u2 = np.zeros(n_points)\n    \n    for i, depth in enumerate(depths):\n        if depth < 3:\n            qc[i] = 1500 + np.random.normal(0, 200)\n            fs[i] = 20 + np.random.normal(0, 3)\n            u2[i] = 50 + depth * 10 + np.random.normal(0, 10)\n        \n        elif depth < 7:\n            qc[i] = 800 + np.random.normal(0, 100)\n            fs[i] = 30 + np.random.normal(0, 5)\n            u2[i] = 100 + depth * 10 + np.random.normal(0, 15)\n        \n        elif depth < 12:\n            qc[i] = 3000 + np.random.normal(0, 300)\n            fs[i] = 40 + np.random.normal(0, 5)\n            u2[i] = 150 + depth * 10 + np.random.normal(0, 20)\n        \n        elif depth < 16:\n            qc[i] = 1200 + np.random.normal(0, 150)\n            fs[i] = 35 + np.random.normal(0, 5)\n            u2[i] = 200 + depth * 10 + np.random.normal(0, 15)\n        \n        else:\n            qc[i] = 5000 + np.random.normal(0, 500)\n            fs[i] = 60 + np.random.normal(0, 8)\n            u2[i] = 250 + depth * 10 + np.random.normal(0, 25)\n    \n    qc = np.maximum(qc, 100)\n    fs = np.maximum(fs, 5)\n    u2 = np.maximum(u2, 0)\n    \n    df = pd.DataFrame({\n        'Depth (m)': depths,\n        'Cone Resistance qc (kPa)': qc,\n        'Sleeve Friction fs (kPa)': fs,\n        'Pore Pressure u2 (kPa)': u2\n    })\n    \n    return df\n\nif __name__ == \"__main__\":\n    df1 = create_sample_cpt_data()\n    df1.to_excel('Sample_CPT_01.xlsx', index=False)\n    print(\"Sample CPT data file created: Sample_CPT_01.xlsx\")\n    \n    np.random.seed(123)\n    df2 = create_sample_cpt_data()\n    df2.to_excel('Sample_CPT_02.xlsx', index=False)\n    print(\"Sample CPT data file created: Sample_CPT_02.xlsx\")\n","size_bytes":2042},"README.md":{"content":"# CPT Analysis & Settlement Calculator\n\nA comprehensive geotechnical engineering web application for analyzing Cone Penetration Test (CPT) data and calculating settlement using Settle3 correlations and methodologies.\n\n## Features\n\n### 1. CPT Data Processing\n- **Excel file upload** supporting multiple CPT datasets\n- Automatic column detection for depth, qc, fs, and u2\n- Normalization calculations (Qt, Fr, Bq, Ic) using Robertson methodology\n- Support for various data formats and headers\n\n### 2. Soil Classification\n- **Robertson (2009)** soil classification charts\n- Automated soil behavior type identification\n- Interactive Qt-Fr classification plots with Ic contours\n- Soil type distribution analysis\n\n### 3. Automated Soil Layering\n- Layer identification based on Ic transitions\n- User-adjustable minimum layer thickness\n- Automatic merging of thin layers\n- Visual layer profiles with depth and thickness\n\n### 4. CPT Correlations\nCalculate key settlement parameters from CPT data:\n- **Young's Modulus (E)** - for immediate settlement\n- **Constrained Modulus (M)**\n- **Compression Index (Cc)** - for consolidation settlement\n- **Recompression Index (Cr)**\n- **Over-Consolidation Ratio (OCR)**\n- **Friction Angle (Ï†)** - for sandy soils\n- **Undrained Shear Strength (Su)** - for clayey soils\n- **Permeability (k)**\n\n### 5. Settlement Analysis\n- **Immediate (Elastic) Settlement** calculations\n- **Consolidation Settlement** for clay layers\n- Total settlement estimation\n- Layer-by-layer settlement breakdown\n- Support for various loading configurations\n\n### 6. Interactive Visualizations\n- CPT profile plots (qc, fs, u2, Qt, Ic)\n- Robertson classification charts with data points\n- Parameter correlation graphs\n- Settlement distribution by layer\n- Multi-CPT comparison views\n\n### 7. Export Functionality\n- **Excel** exports with complete analysis data\n- **PDF** comprehensive reports\n- **CSV** layer summaries\n- Settlement calculation results\n\n## How to Use\n\n### 1. Upload CPT Data\n- Navigate to the \"ðŸ“¤ Upload CPT Data\" tab\n- Upload one or more Excel files containing CPT data\n- Files should have columns for: Depth, qc (cone resistance), fs (sleeve friction), and optionally u2 (pore pressure)\n- The app will automatically detect column names\n\n### 2. Configure Parameters\nUse the sidebar to set:\n- **Unit Weight of Soil** (kN/mÂ³)\n- **Water Table Depth** (m)\n- **Minimum Layer Thickness** (m)\n- **Net Area Ratio** for cone\n\n### 3. View CPT Profiles\n- Select CPTs to display\n- Choose profile type (qc, Rf, u2, Qt, Ic)\n- Compare multiple CPTs side-by-side\n\n### 4. Explore Soil Classification\n- View Robertson (2009) classification charts\n- See soil type distribution\n- Analyze Ic contours\n\n### 5. Review Soil Layers\n- View automated layer identification\n- Export layer data\n- Adjust layer thickness parameters if needed\n\n### 6. Analyze Correlations\n- Review calculated parameters for each layer\n- Compare E, Cc, Cr, OCR across layers\n- Export complete analysis to Excel\n\n### 7. Calculate Settlement\n- Input loading configuration:\n  - Applied load (kN)\n  - Footing dimensions (m)\n  - Footing depth (m)\n- View immediate and consolidation settlement\n- Export settlement results and PDF reports\n\n## Sample Data\n\nSample CPT data files are included:\n- `Sample_CPT_01.xlsx` - Typical multi-layer soil profile\n- `Sample_CPT_02.xlsx` - Alternative soil profile\n\n## Methodology\n\n### Soil Classification\nBased on **Robertson (2009)** normalized CPT methodology:\n- Normalized cone resistance: Qt = (qt - Ïƒvo) / Ïƒ'vo\n- Normalized friction ratio: Fr = [fs / (qt - Ïƒvo)] Ã— 100%\n- Soil behavior type index: Ic = âˆš[(3.47 - log Qt)Â² + (log Fr + 1.22)Â²]\n\n### Correlations\nSettlement parameters derived from published correlations:\n- **E**: Î±_E Ã— (qt - Ïƒvo), where Î±_E = 0.015 Ã— 10^(0.55Ã—Ic + 1.68)\n- **Cc**: Based on plasticity index correlations (Jain et al. 2015)\n- **Cr**: GMDH-type neural network (Kordnaeij et al. 2015)\n- **OCR**: k Ã— (qt / Ïƒ'vo), where k varies with soil type\n- **M**: Î±_M Ã— qt, where Î±_M varies with Qtn\n\n### Settlement Calculations\n- **Immediate Settlement**: S = Î£(Î”Ïƒ Ã— H / E) for each layer\n- **Consolidation Settlement**: Terzaghi's theory with Cc and Cr\n- Accounts for over-consolidation and stress history\n\n## Technical Details\n\n### Built With\n- **Streamlit** - Web application framework\n- **Pandas** - Data processing\n- **NumPy** - Numerical calculations\n- **Plotly** - Interactive visualizations\n- **SciPy** - Scientific computations\n- **FPDF** - PDF report generation\n\n### References\n- Robertson, P.K. (2009). \"Interpretation of cone penetration tests - a unified approach\"\n- Settle3 CPT Theory Manual (Rocscience)\n- Terzaghi's Consolidation Theory\n\n## Notes\n\n- The app performs calculations based on empirical correlations which have limitations\n- Results should be verified by qualified geotechnical engineers\n- Engineering judgment is required for final design decisions\n- Parameters may need adjustment based on local experience and soil conditions\n\n## Support\n\nFor questions about geotechnical engineering principles or settlement calculations, consult relevant technical literature and standards.\n","size_bytes":5148},"replit.md":{"content":"# CPT Analysis & Settlement Calculator\n\n## Overview\n\nThis is a comprehensive geotechnical engineering web application built with Streamlit for analyzing Cone Penetration Test (CPT) data and calculating settlement predictions. The application implements Settle3 correlations and Robertson (2009) methodologies to process field CPT data, classify soils, identify soil layers, and estimate both immediate and consolidation settlements for foundation design.\n\nThe system provides an end-to-end workflow from uploading raw CPT Excel data through automated soil profiling to generating settlement calculations with visual analytics and exportable reports.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Application Framework\n- **Frontend & Backend**: Streamlit single-file application (`app.py`) serving as the main UI controller\n- **Session State Management**: Uses Streamlit's session state to persist CPT datasets and processed results across user interactions\n- **Modular Design**: Functionality separated into domain-specific modules (processing, classification, correlations, settlement, export)\n\n### Core Processing Pipeline\n\n**CPT Data Processing** (`cpt_processor.py`)\n- Flexible file parser supporting both Excel (.xlsx, .xls) and text files (.txt, .csv)\n- Text parser auto-detects delimiters (comma, tab, semicolon, space)\n- Automatic column detection using keyword matching for various naming conventions\n- Handles depth, cone resistance (qc), sleeve friction (fs), and pore pressure (u2)\n- Implements Robertson (2009) normalization calculations for Qt, Fr, Bq, and Ic parameters\n- Uses atmospheric pressure reference (Pa = 100 kPa) and standard water unit weight\n\n**Soil Classification** (`soil_classification.py`)\n- Automated soil behavior type identification using Robertson classification charts\n- Layer detection algorithm based on Ic value transitions with configurable threshold (0.3 change)\n- Moving window approach to identify layer boundaries\n- Minimum layer thickness enforcement with layer merging capability\n- Creates comprehensive layer profiles with depth ranges and soil type classifications\n\n**Geotechnical Correlations** (`correlations.py`)\n- Implements multiple CPT-to-soil parameter correlations following Settle3 methodology\n- Young's Modulus (E) calculation: alpha_E = 0.015 * 10^(0.55*Ic + 1.68)\n- Constrained Modulus (M) with Qtn-based alpha_M factors (limited to 2-8 range)\n- Compression Index (Cc), Recompression Index (Cr), and OCR calculations\n- Parameter bounds enforcement to ensure physical validity\n\n**Settlement Calculations** (`settlement_calc.py`)\n- Boussinesq elastic theory implementation for stress distribution\n- Simplified 2:1 method for rectangular footing stress propagation\n- Immediate (elastic) settlement using Young's Modulus\n- Consolidation settlement for clay layers using compression indices\n- Layer-by-layer breakdown with stress increase validation\n- Ensures stress only spreads below footing base level\n\n### Data Visualization\n- **Plotly Integration**: Interactive charts using plotly.graph_objects and plotly.express\n- Multi-subplot layouts for CPT profile visualization (qc, fs, u2, Qt, Ic)\n- Robertson classification charts with data point overlays and Ic contours\n- Settlement distribution visualizations by layer\n- Multi-CPT comparison capabilities\n\n### Export & Reporting\n**Export Manager** (`export_utils.py`)\n- Excel export functionality using pandas for structured data output\n- Custom PDF report generation using FPDF library\n- Includes CPT data, layer definitions, calculated parameters, and settlement results\n- Timestamped reports with formatted tables and headers\n\n### Configuration & Parameters\n**User-Configurable Settings** (via sidebar)\n- Soil unit weight (14-25 kN/mÂ³, default 18.0)\n- Water table depth (0-50m, default 2.0m)\n- Minimum layer thickness (0.1-5.0m, default 0.5m)\n- Net area ratio for CPT corrections (0.5-1.0, default 0.8)\n\n### Data Flow Architecture\n1. User uploads CPT data (Excel or text files) â†’ CPTProcessor validates and normalizes\n2. Normalized data â†’ RobertsonClassification assigns soil types\n3. Classified data â†’ SoilLayering identifies distinct layers\n4. Layers + CPT data â†’ CPTCorrelations calculates settlement parameters\n5. Parameters + loading conditions â†’ SettlementCalculator computes settlements\n6. Results â†’ ExportManager generates reports and downloads\n\n### Testing & Sample Data\n- `sample_cpt_data.py` provides synthetic CPT profiles for testing\n- Simulates realistic soil profiles with sandy and clayey layer transitions\n- Uses seeded random variations to mimic field data variability\n\n## External Dependencies\n\n### Python Libraries\n- **streamlit**: Web application framework for UI and session management\n- **pandas**: Data manipulation and Excel file I/O\n- **numpy**: Numerical computations and array operations\n- **plotly**: Interactive visualization library (graph_objects, express, subplots)\n- **fpdf**: PDF report generation\n- **openpyxl** (implicit): Excel file reading backend for pandas\n\n### Geotechnical Standards\n- Robertson (2009) CPT interpretation methodology\n- Settle3 settlement calculation correlations\n- Boussinesq elastic theory for stress distribution\n- Terzaghi's consolidation theory\n\n### File Formats\n- **Input**: Excel files (.xlsx, .xls) and text files (.txt, .csv) with flexible column naming and automatic delimiter detection\n- **Output**: Excel workbooks with multiple sheets, PDF reports\n\n### Potential Future Integrations\nThe architecture supports future addition of:\n- Database persistence for CPT data storage (currently in-memory session state)\n- User authentication for multi-user project management\n- Cloud storage integration for file uploads\n- Additional correlation methods (Schmertmann, Mayne & Poulos)\n- 3D visualization of multiple CPT locations\n- Automated report emailing functionality","size_bytes":5915},"settlement_calc.py":{"content":"import numpy as np\nimport pandas as pd\nfrom typing import Dict, List, Tuple\n\nclass SettlementCalculator:\n    \"\"\"\n    Settlement calculation engine for immediate and consolidation settlement.\n    Based on elastic theory and Terzaghi's consolidation theory.\n    \"\"\"\n    \n    def __init__(self):\n        pass\n    \n    def calculate_stress_increase(self, load: float, footing_width: float, \n                                 footing_length: float, depth_below_footing: float,\n                                 layer_thickness: float) -> float:\n        \"\"\"\n        Calculate stress increase at depth using Boussinesq elastic theory.\n        Simplified using 2:1 method for rectangular footings.\n        \n        Parameters:\n        - load: Applied load in kN\n        - footing_width: Width of footing in m\n        - footing_length: Length of footing in m  \n        - depth_below_footing: Depth to layer center below footing base (z) in m\n        - layer_thickness: Thickness of layer in m\n        \n        Returns:\n        - Average stress increase in the layer (kPa)\n        \n        Note: Returns 0 for any layer with top above or at footing base.\n        Stress only spreads below the footing base.\n        \"\"\"\n        # Contact pressure\n        q0 = load / (footing_width * footing_length)\n        \n        # Calculate depths to top and bottom of layer\n        depth_to_top = depth_below_footing - layer_thickness / 2\n        depth_to_bottom = depth_below_footing + layer_thickness / 2\n        \n        # If entire layer or any part of layer is above footing base, no stress\n        if depth_to_top <= 0:\n            return 0.0\n        \n        # Both top and bottom are below footing base\n        # 2:1 distribution method: stress spreads at 2V:1H ratio from footing base\n        width_at_top = footing_width + depth_to_top\n        length_at_top = footing_length + depth_to_top\n        width_at_bottom = footing_width + depth_to_bottom\n        length_at_bottom = footing_length + depth_to_bottom\n        \n        # Stress at top and bottom of layer\n        delta_sigma_top = q0 * (footing_width * footing_length) / (width_at_top * length_at_top)\n        delta_sigma_bottom = q0 * (footing_width * footing_length) / (width_at_bottom * length_at_bottom)\n        \n        # Average stress over the layer\n        delta_sigma_avg = (delta_sigma_top + delta_sigma_bottom) / 2\n        \n        return delta_sigma_avg\n    \n    def calculate_immediate_settlement(self, layers_params: pd.DataFrame, \n                                      load: float, footing_width: float,\n                                      footing_length: float,\n                                      footing_depth: float = 0.0,\n                                      poisson_ratio: float = 0.3) -> Dict:\n        \"\"\"\n        Calculate immediate (elastic) settlement.\n        \n        S_immediate = Î£ (Î”Ïƒ * H * (1 - Î½Â²) / E) for each layer\n        \n        where:\n        - Î”Ïƒ = stress increase in layer\n        - H = layer thickness\n        - Î½ = Poisson's ratio\n        - E = Young's modulus\n        \"\"\"\n        if len(layers_params) == 0:\n            return {'total_settlement': 0, 'layer_settlements': []}\n        \n        layer_settlements = []\n        total_settlement = 0\n        \n        # Cumulative depth from ground surface\n        cumulative_depth = footing_depth\n        \n        for _, layer in layers_params.iterrows():\n            # Depth to center of layer from ground surface\n            layer_mid_depth_from_surface = cumulative_depth + layer['thickness'] / 2\n            \n            # Depth below footing base (measured from footing base, not surface)\n            depth_below_footing = layer_mid_depth_from_surface - footing_depth\n            \n            # Stress increase (using depth below footing)\n            delta_sigma = self.calculate_stress_increase(\n                load, footing_width, footing_length, \n                depth_below_footing, layer['thickness']\n            )\n            \n            # Young's modulus\n            E = layer['youngs_modulus']\n            \n            # Settlement of this layer (elastic) with Poisson's ratio correction\n            # S = Î”Ïƒ * H * (1 - Î½Â²) / E\n            elastic_correction = 1 - poisson_ratio**2\n            layer_settlement = (delta_sigma * layer['thickness'] * elastic_correction * 1000) / E  # in mm\n            \n            layer_settlements.append({\n                'layer_number': layer['layer_number'],\n                'soil_type': layer['soil_type'],\n                'settlement_mm': layer_settlement,\n                'stress_increase_kPa': delta_sigma,\n                'E_kPa': E\n            })\n            \n            total_settlement += layer_settlement\n            cumulative_depth += layer['thickness']\n        \n        return {\n            'total_settlement_mm': total_settlement,\n            'layer_settlements': layer_settlements\n        }\n    \n    def calculate_consolidation_settlement(self, layers_params: pd.DataFrame,\n                                          load: float, footing_width: float,\n                                          footing_length: float,\n                                          footing_depth: float = 0.0,\n                                          water_table_depth: float = 2.0) -> Dict:\n        \"\"\"\n        Calculate consolidation settlement for clay layers.\n        \n        For normally consolidated (Ïƒ'0 + Î”Ïƒ <= Ïƒ'p):\n            S_c = (Cr * H / (1 + e0)) * log10(Ïƒ'p / Ïƒ'0) + \n                  (Cc * H / (1 + e0)) * log10((Ïƒ'0 + Î”Ïƒ) / Ïƒ'p)\n        \n        For overconsolidated (Ïƒ'0 + Î”Ïƒ > Ïƒ'p):\n            S_c = (Cc * H / (1 + e0)) * log10((Ïƒ'0 + Î”Ïƒ) / Ïƒ'0)\n        \n        where:\n        - Cc = compression index\n        - Cr = recompression index\n        - H = layer thickness\n        - e0 = initial void ratio (estimated)\n        - Ïƒ'0 = initial effective stress\n        - Ïƒ'p = preconsolidation pressure\n        - Î”Ïƒ = stress increase\n        \"\"\"\n        if len(layers_params) == 0:\n            return {'total_settlement': 0, 'layer_settlements': []}\n        \n        layer_settlements = []\n        total_settlement = 0\n        \n        cumulative_depth = footing_depth\n        gamma_soil = 18.0  # kN/mÂ³\n        gamma_water = 9.81  # kN/mÂ³\n        \n        for _, layer in layers_params.iterrows():\n            # Only calculate for clay-like soils (Ic > 2.6)\n            if layer['Ic'] < 2.6:\n                layer_settlements.append({\n                    'layer_number': layer['layer_number'],\n                    'soil_type': layer['soil_type'],\n                    'settlement_mm': 0.0,\n                    'note': 'Granular soil - no consolidation settlement'\n                })\n                cumulative_depth += layer['thickness']\n                continue\n            \n            # Depth to center of layer from ground surface\n            layer_mid_depth_from_surface = cumulative_depth + layer['thickness'] / 2\n            \n            # Initial effective stress at mid-depth\n            sigma_v0 = gamma_soil * layer_mid_depth_from_surface\n            if layer_mid_depth_from_surface > water_table_depth:\n                u0 = gamma_water * (layer_mid_depth_from_surface - water_table_depth)\n            else:\n                u0 = 0\n            sigma_v0_prime = sigma_v0 - u0\n            \n            # Depth below footing base (measured from footing base, not surface)\n            depth_below_footing = layer_mid_depth_from_surface - footing_depth\n            \n            # Stress increase (using depth below footing)\n            delta_sigma = self.calculate_stress_increase(\n                load, footing_width, footing_length,\n                depth_below_footing, layer['thickness']\n            )\n            \n            # Preconsolidation pressure from OCR\n            OCR = layer['OCR']\n            sigma_p = sigma_v0_prime * OCR\n            \n            # Compression and recompression indices\n            Cc = layer['compression_index']\n            Cr = layer['recompression_index']\n            \n            # Estimate void ratio from Ic and soil type\n            # Higher Ic (clay) typically has higher void ratio\n            if layer['Ic'] > 3.5:\n                e0 = 1.0  # Soft clay\n            elif layer['Ic'] > 3.0:\n                e0 = 0.8  # Medium clay\n            else:\n                e0 = 0.6  # Stiff silt/clay\n            \n            # Calculate settlement based on stress state\n            H_meters = layer['thickness']\n            \n            if sigma_v0_prime + delta_sigma <= sigma_p:\n                # Overconsolidated - all in recompression range\n                S_c = (Cr * H_meters / (1 + e0)) * np.log10((sigma_v0_prime + delta_sigma) / sigma_v0_prime)\n                condition = \"Overconsolidated (recompression only)\"\n            else:\n                if sigma_v0_prime < sigma_p:\n                    # Starts overconsolidated, becomes normally consolidated\n                    S_c_recomp = (Cr * H_meters / (1 + e0)) * np.log10(sigma_p / sigma_v0_prime)\n                    S_c_virgin = (Cc * H_meters / (1 + e0)) * np.log10((sigma_v0_prime + delta_sigma) / sigma_p)\n                    S_c = S_c_recomp + S_c_virgin\n                    condition = \"Overconsolidated to normally consolidated\"\n                else:\n                    # Normally consolidated\n                    S_c = (Cc * H_meters / (1 + e0)) * np.log10((sigma_v0_prime + delta_sigma) / sigma_v0_prime)\n                    condition = \"Normally consolidated\"\n            \n            # Convert to mm\n            S_c_mm = S_c * 1000\n            \n            layer_settlements.append({\n                'layer_number': layer['layer_number'],\n                'soil_type': layer['soil_type'],\n                'settlement_mm': S_c_mm,\n                'stress_increase_kPa': delta_sigma,\n                'initial_stress_kPa': sigma_v0_prime,\n                'preconsolidation_kPa': sigma_p,\n                'OCR': OCR,\n                'Cc': Cc,\n                'Cr': Cr,\n                'condition': condition\n            })\n            \n            total_settlement += S_c_mm\n            cumulative_depth += layer['thickness']\n        \n        return {\n            'total_settlement_mm': total_settlement,\n            'layer_settlements': layer_settlements\n        }\n    \n    def calculate_total_settlement(self, layers_params: pd.DataFrame,\n                                  load: float, footing_width: float,\n                                  footing_length: float,\n                                  footing_depth: float = 0.0,\n                                  water_table_depth: float = 2.0) -> Dict:\n        \"\"\"\n        Calculate total settlement (immediate + consolidation).\n        \"\"\"\n        immediate = self.calculate_immediate_settlement(\n            layers_params, load, footing_width, footing_length, footing_depth\n        )\n        \n        consolidation = self.calculate_consolidation_settlement(\n            layers_params, load, footing_width, footing_length, \n            footing_depth, water_table_depth\n        )\n        \n        total = immediate['total_settlement_mm'] + consolidation['total_settlement_mm']\n        \n        return {\n            'immediate_settlement_mm': immediate['total_settlement_mm'],\n            'consolidation_settlement_mm': consolidation['total_settlement_mm'],\n            'total_settlement_mm': total,\n            'immediate_details': immediate['layer_settlements'],\n            'consolidation_details': consolidation['layer_settlements']\n        }\n    \n    def estimate_time_settlement(self, layers_params: pd.DataFrame,\n                                load: float, footing_width: float,\n                                footing_length: float,\n                                time_years: float = 1.0,\n                                footing_depth: float = 0.0,\n                                water_table_depth: float = 2.0) -> Dict:\n        \"\"\"\n        Estimate settlement at a given time using consolidation theory.\n        \n        Uses average degree of consolidation (U) based on time factor (Tv).\n        \"\"\"\n        consolidation = self.calculate_consolidation_settlement(\n            layers_params, load, footing_width, footing_length,\n            footing_depth, water_table_depth\n        )\n        \n        total_time_settlement = 0\n        layer_time_settlements = []\n        \n        for layer_detail in consolidation['layer_settlements']:\n            if 'Cc' not in layer_detail:\n                # Granular layer - immediate settlement only\n                layer_time_settlements.append({\n                    'layer_number': layer_detail['layer_number'],\n                    'settlement_mm': 0.0,\n                    'degree_consolidation': 1.0\n                })\n                continue\n            \n            # Get layer info\n            layer_idx = int(layer_detail['layer_number']) - 1\n            layer = layers_params.iloc[layer_idx]\n            \n            # Permeability and thickness\n            k = layer['permeability']  # m/s\n            H_drainage = layer['thickness'] / 2  # Assume double drainage\n            \n            # Coefficient of consolidation\n            # cv = k / (gamma_w * mv)\n            # mv = (1 + e0) / (Cc * sigma_v')  approximation\n            gamma_w = 9.81  # kN/mÂ³\n            Cc = layer_detail['Cc']\n            sigma_v_prime = layer_detail['initial_stress_kPa']\n            e0 = 0.8  # Assumed\n            \n            mv = Cc / ((1 + e0) * sigma_v_prime * np.log(10))  # mÂ²/kN\n            cv = k / (gamma_w * mv)  # mÂ²/s\n            \n            # Time factor\n            time_seconds = time_years * 365.25 * 24 * 3600\n            Tv = cv * time_seconds / (H_drainage ** 2)\n            \n            # Degree of consolidation (Terzaghi theory)\n            # Correct formula: U = 1 - (8/Ï€Â²) * exp(-Ï€Â²*Tv/4)\n            if Tv < 0.217:\n                U = np.sqrt(4 * Tv / np.pi)\n            else:\n                U = 1 - (8 / (np.pi ** 2)) * np.exp(-np.pi ** 2 * Tv / 4)\n            \n            U = min(U, 1.0)\n            \n            settlement_at_time = layer_detail['settlement_mm'] * U\n            total_time_settlement += settlement_at_time\n            \n            layer_time_settlements.append({\n                'layer_number': layer_detail['layer_number'],\n                'settlement_mm': settlement_at_time,\n                'degree_consolidation': U,\n                'time_factor': Tv\n            })\n        \n        return {\n            'time_years': time_years,\n            'total_settlement_mm': total_time_settlement,\n            'layer_settlements': layer_time_settlements\n        }\n    \n    def generate_time_settlement_curve(self, layers_params: pd.DataFrame,\n                                      load: float, footing_width: float,\n                                      footing_length: float,\n                                      max_time_years: float = 50.0,\n                                      num_points: int = 100,\n                                      footing_depth: float = 0.0,\n                                      water_table_depth: float = 2.0,\n                                      include_secondary: bool = True,\n                                      c_alpha: float = 0.02) -> Dict:\n        \"\"\"\n        Generate settlement vs time curve for consolidation analysis.\n        \n        Parameters:\n        - max_time_years: Maximum time to simulate (years)\n        - num_points: Number of time points to calculate\n        - include_secondary: Whether to include secondary compression (creep)\n        - c_alpha: Secondary compression index (C_alpha / Cc ratio, typical 0.02-0.05)\n        \n        Returns:\n        - Dictionary with time arrays and settlement data\n        \"\"\"\n        # Get immediate settlement (happens instantaneously)\n        immediate = self.calculate_immediate_settlement(\n            layers_params, load, footing_width, footing_length, footing_depth\n        )\n        \n        # Get final consolidation settlement\n        consolidation = self.calculate_consolidation_settlement(\n            layers_params, load, footing_width, footing_length,\n            footing_depth, water_table_depth\n        )\n        \n        # Generate time points (logarithmic spacing for better resolution)\n        time_points = np.logspace(-3, np.log10(max_time_years), num_points)  # From 0.001 to max_time_years\n        \n        # Arrays to store results\n        settlement_primary = []\n        settlement_with_secondary = []\n        layer_contributions = {i: [] for i in range(len(layers_params))}\n        \n        for time_years in time_points:\n            # Calculate total settlement at this time (immediate + time-dependent consolidation)\n            # Start at 0 and add each layer's contribution once\n            total_primary = 0\n            \n            for idx, layer_detail in enumerate(consolidation['layer_settlements']):\n                # Get immediate settlement for this layer\n                layer_immediate = 0\n                if idx < len(immediate['layer_settlements']):\n                    layer_immediate = immediate['layer_settlements'][idx]['settlement_mm']\n                \n                if 'Cc' not in layer_detail:\n                    # Granular layer - only immediate settlement (no consolidation)\n                    layer_settlement = layer_immediate\n                else:\n                    # Clay layer - calculate time-dependent consolidation\n                    layer_idx = int(layer_detail['layer_number']) - 1\n                    layer = layers_params.iloc[layer_idx]\n                    \n                    # Permeability and drainage conditions\n                    k = layer['permeability']  # m/s\n                    H_drainage = layer['thickness'] / 2  # Assume double drainage\n                    \n                    # Coefficient of consolidation\n                    gamma_w = 9.81  # kN/mÂ³\n                    Cc = layer_detail['Cc']\n                    sigma_v_prime = layer_detail['initial_stress_kPa']\n                    e0 = 0.8  # Assumed\n                    \n                    mv = Cc / ((1 + e0) * sigma_v_prime * np.log(10))  # mÂ²/kN\n                    cv = k / (gamma_w * mv)  # mÂ²/s\n                    \n                    # Time factor\n                    time_seconds = time_years * 365.25 * 24 * 3600\n                    Tv = cv * time_seconds / (H_drainage ** 2)\n                    \n                    # Degree of consolidation (Terzaghi theory)\n                    # Correct formula: U = 1 - (8/Ï€Â²) * exp(-Ï€Â²*Tv/4)\n                    if Tv < 0.217:\n                        U = np.sqrt(4 * Tv / np.pi)\n                    else:\n                        U = 1 - (8 / (np.pi ** 2)) * np.exp(-np.pi ** 2 * Tv / 4)\n                    U = min(U, 1.0)\n                    \n                    # Layer settlement = immediate + (consolidation settlement * degree of consolidation)\n                    layer_settlement = layer_immediate + layer_detail['settlement_mm'] * U\n                \n                total_primary += layer_settlement\n                layer_contributions[idx].append(layer_settlement)\n            \n            settlement_primary.append(total_primary)\n            \n            # Add secondary compression (creep) if requested\n            if include_secondary:\n                # Secondary compression starts after primary consolidation\n                # S_secondary = C_alpha * H * log10(t/t_p)\n                # where t_p is time for primary consolidation (typically at U = 90%)\n                \n                secondary_settlement = 0\n                for layer_detail in consolidation['layer_settlements']:\n                    if 'Cc' not in layer_detail:\n                        continue\n                    \n                    layer_idx = int(layer_detail['layer_number']) - 1\n                    layer = layers_params.iloc[layer_idx]\n                    \n                    # Estimate time for 90% consolidation\n                    k = layer['permeability']\n                    H_drainage = layer['thickness'] / 2\n                    Cc = layer_detail['Cc']\n                    sigma_v_prime = layer_detail['initial_stress_kPa']\n                    e0 = 0.8\n                    mv = Cc / ((1 + e0) * sigma_v_prime * np.log(10))\n                    cv = k / (9.81 * mv)\n                    \n                    # Tv for 90% consolidation â‰ˆ 0.848\n                    t_p_seconds = 0.848 * (H_drainage ** 2) / cv\n                    t_p_years = t_p_seconds / (365.25 * 24 * 3600)\n                    \n                    # Secondary compression only occurs after primary\n                    if time_years > t_p_years:\n                        C_alpha = c_alpha * Cc  # Secondary compression index\n                        H_meters = layer['thickness']\n                        S_secondary = (C_alpha * H_meters / (1 + e0)) * np.log10(time_years / t_p_years)\n                        secondary_settlement += S_secondary * 1000  # Convert to mm\n                \n                settlement_with_secondary.append(total_primary + secondary_settlement)\n            else:\n                settlement_with_secondary.append(total_primary)\n        \n        return {\n            'time_years': time_points.tolist(),\n            'settlement_primary_mm': settlement_primary,\n            'settlement_total_mm': settlement_with_secondary,\n            'immediate_settlement_mm': immediate['total_settlement_mm'],\n            'final_consolidation_mm': consolidation['total_settlement_mm'],\n            'layer_contributions': layer_contributions,\n            'secondary_compression_included': include_secondary,\n            'c_alpha': c_alpha if include_secondary else 0\n        }\n    \n    def calculate_consolidation_time(self, layers_params: pd.DataFrame,\n                                    target_degree: float = 0.90) -> Dict:\n        \"\"\"\n        Calculate time required to achieve a target degree of consolidation.\n        \n        Parameters:\n        - target_degree: Target degree of consolidation (0-1), typically 0.90\n        \n        Returns:\n        - Dictionary with consolidation times for each layer\n        \"\"\"\n        # Time factor for different degrees of consolidation\n        if target_degree < 0.5:\n            Tv_target = (np.pi / 4) * (target_degree ** 2)\n        elif target_degree < 0.60:\n            Tv_target = 0.197\n        elif target_degree < 0.90:\n            # Interpolate\n            Tv_target = -0.933 * np.log10(1 - target_degree)\n        else:\n            Tv_target = -0.933 * np.log10(1 - target_degree)\n        \n        layer_times = []\n        \n        for _, layer in layers_params.iterrows():\n            # Only for clay layers\n            if layer['Ic'] < 2.6:\n                layer_times.append({\n                    'layer_number': layer['layer_number'],\n                    'soil_type': layer['soil_type'],\n                    'time_years': 0,\n                    'note': 'Granular soil - immediate settlement'\n                })\n                continue\n            \n            # Drainage conditions\n            k = layer['permeability']  # m/s\n            H_drainage = layer['thickness'] / 2  # Assume double drainage\n            \n            # Estimate consolidation parameters\n            gamma_w = 9.81  # kN/mÂ³\n            # Estimate Cc from Ic\n            Ic = layer['Ic']\n            Cc = max(0.009 * (Ic - 1.5), 0.05)\n            \n            # Estimate effective stress\n            depth = layer['top_depth'] + layer['thickness'] / 2\n            sigma_v_prime = 18.0 * depth - 9.81 * max(0, depth - 2.0)\n            \n            e0 = 0.8\n            mv = Cc / ((1 + e0) * sigma_v_prime * np.log(10))\n            cv = k / (gamma_w * mv)  # mÂ²/s\n            \n            # Time for target consolidation\n            time_seconds = Tv_target * (H_drainage ** 2) / cv\n            time_years = time_seconds / (365.25 * 24 * 3600)\n            \n            layer_times.append({\n                'layer_number': layer['layer_number'],\n                'soil_type': layer['soil_type'],\n                'thickness_m': layer['thickness'],\n                'permeability_m_s': k,\n                'cv_m2_s': cv,\n                'time_years': time_years,\n                'time_days': time_years * 365.25,\n                'target_degree': target_degree\n            })\n        \n        return {\n            'target_degree': target_degree,\n            'layer_times': layer_times\n        }\n","size_bytes":24481},"correlations.py":{"content":"import numpy as np\nimport pandas as pd\nfrom typing import Dict\n\nclass CPTCorrelations:\n    \"\"\"\n    CPT correlations for settlement parameters based on Settle3 methodology.\n    Includes correlations for E, Cc, Cr, M, OCR and other parameters.\n    \"\"\"\n    \n    def __init__(self):\n        self.Pa = 100.0  # Atmospheric pressure in kPa\n    \n    def calculate_youngs_modulus(self, qt: float, sigma_vo: float, Ic: float) -> float:\n        \"\"\"\n        Calculate Young's Modulus (E) from CPT data.\n        \n        Based on Robertson (2009):\n        E = alpha_E * (qt - sigma_vo)\n        where alpha_E = 0.015 * 10^(0.55*Ic + 1.68)\n        \n        The modulus is mobilized at about 0.1% strain.\n        \"\"\"\n        alpha_E = 0.015 * (10 ** (0.55 * Ic + 1.68))\n        E = alpha_E * (qt - sigma_vo)\n        return max(E, 100)  # Minimum 100 kPa\n    \n    def calculate_constrained_modulus(self, qt: float, Qtn: float) -> float:\n        \"\"\"\n        Calculate Constrained Modulus (M) from CPT data.\n        \n        Based on Robertson (2009):\n        M = alpha_M * qt\n        where alpha_M varies with Qtn, limited to 8\n        \"\"\"\n        # Calculate alpha_M based on Qtn\n        if Qtn < 14:\n            alpha_M = Qtn * 0.5\n        else:\n            alpha_M = 8.0  # Maximum value limited to 8\n        \n        alpha_M = min(alpha_M, 8.0)\n        alpha_M = max(alpha_M, 2.0)  # Minimum value of 2\n        \n        M = alpha_M * qt\n        return max(M, 100)\n    \n    def calculate_compression_index(self, Ic: float, sigma_vo_prime: float, \n                                   qt: float, PI: float = None) -> float:\n        \"\"\"\n        Calculate Compression Index (Cc) from CPT data.\n        \n        Based on correlations from plasticity index (Jain et al. 2015)\n        For clay-like soils (Ic > 2.6)\n        \n        If PI not available, estimate from Ic\n        \"\"\"\n        if Ic < 2.6:\n            # Sandy soils - low compressibility\n            Cc = 0.01 + 0.05 * (Ic - 1.5)\n            Cc = max(0.01, min(Cc, 0.1))\n        else:\n            # Clay-like soils\n            if PI is None:\n                # Estimate PI from Ic\n                # Higher Ic suggests higher plasticity\n                PI_estimated = (Ic - 2.6) * 15\n                PI = min(PI_estimated, 60)\n            \n            # Correlation: Cc = 0.009 * (LL - 10) or Cc = 0.007 * (PI + 5)\n            # Using PI correlation\n            Cc = 0.007 * (PI + 5)\n            \n            # Alternative based on qt for fine-grained soils\n            if qt < 1000:  # Soft clay\n                Cc_alt = 0.5 - 0.0003 * qt\n                Cc = max(Cc, Cc_alt)\n        \n        return max(Cc, 0.01)\n    \n    def calculate_recompression_index(self, Cc: float, LL: float = None, \n                                     Ic: float = None) -> float:\n        \"\"\"\n        Calculate Recompression Index (Cr) from CPT data.\n        \n        Based on GMDH-type neural network (Kordnaeij et al. 2015)\n        Typical relationship: Cr = Cc / 5 to Cc / 10\n        \n        For more accurate results, uses LL (liquid limit) if available\n        \"\"\"\n        if LL is not None:\n            # Correlation with liquid limit\n            Cr = 0.002 * (LL + 10)\n        elif Ic is not None:\n            # Estimate from Ic\n            if Ic > 2.95:  # Clay\n                Cr = Cc / 6.0\n            elif Ic > 2.60:  # Silt\n                Cr = Cc / 8.0\n            else:  # Sand\n                Cr = Cc / 10.0\n        else:\n            # Default relationship\n            Cr = Cc / 7.0\n        \n        return max(Cr, 0.001)\n    \n    def calculate_OCR(self, qt: float, sigma_vo: float, sigma_vo_prime: float, Ic: float) -> float:\n        \"\"\"\n        Calculate Over-Consolidation Ratio (OCR) from CPT data.\n        \n        Based on Chen & Mayne (1996) and Mayne (2005):\n        OCR = k * (qt - sigma_vo) / sigma_vo_prime\n        where k varies with soil type\n        \"\"\"\n        if Ic < 2.2:  # Sand\n            k = 0.33\n        elif Ic < 2.6:  # Silty sand\n            k = 0.30\n        elif Ic < 3.0:  # Silt\n            k = 0.25\n        else:  # Clay\n            k = 0.20\n        \n        # Use net cone resistance (qt - sigma_vo)\n        qnet = qt - sigma_vo\n        OCR = k * (qnet / sigma_vo_prime)\n        \n        # Reasonable bounds\n        OCR = max(1.0, min(OCR, 20.0))\n        \n        return OCR\n    \n    def calculate_friction_angle(self, Qtn: float, Ic: float) -> float:\n        \"\"\"\n        Calculate friction angle (phi) for sandy soils.\n        \n        Based on Robertson & Campanella (1983) and Kulhawy & Mayne (1990)\n        \"\"\"\n        if Ic > 2.6:\n            # Not applicable for clay-like soils\n            return 0.0\n        \n        # Robertson & Campanella correlation\n        if Qtn < 300:\n            phi = 17.6 + 11.0 * np.log10(Qtn)\n        else:\n            phi = 17.6 + 11.0 * np.log10(300)  # Cap at Qtn = 300\n        \n        phi = max(25, min(phi, 45))  # Reasonable bounds\n        \n        return phi\n    \n    def calculate_undrained_shear_strength(self, qt: float, sigma_vo: float, \n                                          Ic: float) -> float:\n        \"\"\"\n        Calculate undrained shear strength (Su) for clay-like soils.\n        \n        Based on Robertson (2009):\n        Su = (qt - sigma_vo) / Nkt\n        where Nkt varies with soil plasticity\n        \"\"\"\n        if Ic < 2.6:\n            # Not applicable for sandy soils\n            return 0.0\n        \n        # Cone factor Nkt varies typically between 10-20\n        # Higher Ic suggests higher plasticity and higher Nkt\n        Nkt = 10 + (Ic - 2.6) * 5\n        Nkt = min(Nkt, 20)\n        \n        Su = (qt - sigma_vo) / Nkt\n        \n        return max(Su, 0)\n    \n    def calculate_permeability(self, Ic: float, qt: float) -> float:\n        \"\"\"\n        Calculate permeability (k) from CPT data.\n        \n        Based on Robertson (2010):\n        log k (m/s) = 0.952 - 3.04 * Ic\n        \"\"\"\n        log_k = 0.952 - 3.04 * Ic\n        k = 10 ** log_k\n        \n        # Reasonable bounds\n        k = max(1e-10, min(k, 1e-3))\n        \n        return k\n    \n    def calculate_unit_weight(self, qt: float, Ic: float) -> float:\n        \"\"\"\n        Calculate bulk unit weight (gamma) from CPT data.\n        \n        Based on Robertson & Cabal (2010)\n        \"\"\"\n        if Ic < 2.05:  # Sand\n            gamma = 17.0 + 3.0 * np.log10(qt / 100)\n        elif Ic < 2.6:  # Silty sand\n            gamma = 16.5 + 2.0 * np.log10(qt / 100)\n        else:  # Clay\n            gamma = 15.0 + 2.5 * np.log10(qt / 100)\n        \n        gamma = max(14.0, min(gamma, 22.0))  # Reasonable bounds\n        \n        return gamma\n    \n    def calculate_all_parameters(self, layer: Dict) -> Dict:\n        \"\"\"\n        Calculate all settlement parameters for a soil layer.\n        \n        Input: layer dictionary from soil layering\n        Output: dictionary with all calculated parameters\n        \"\"\"\n        qt = layer['avg_qt']\n        sigma_vo_prime = layer['avg_sigma_vo_prime']\n        Ic = layer['avg_Ic']\n        Qtn = layer['avg_Qt']\n        \n        # Calculate stress at mid-depth of layer\n        sigma_vo = sigma_vo_prime * 1.2  # Approximate (assumes some pore pressure)\n        \n        parameters = {\n            'layer_number': layer['layer_number'],\n            'soil_type': layer['soil_type'],\n            'thickness': layer['thickness'],\n            'Ic': Ic,\n            \n            # Strength parameters\n            'friction_angle': self.calculate_friction_angle(Qtn, Ic),\n            'undrained_shear_strength': self.calculate_undrained_shear_strength(qt, sigma_vo, Ic),\n            \n            # Stiffness parameters\n            'youngs_modulus': self.calculate_youngs_modulus(qt, sigma_vo, Ic),\n            'constrained_modulus': self.calculate_constrained_modulus(qt, Qtn),\n            \n            # Compressibility parameters\n            'compression_index': self.calculate_compression_index(Ic, sigma_vo_prime, qt),\n            'recompression_index': None,  # Will be calculated after Cc\n            \n            # Stress history\n            'OCR': self.calculate_OCR(qt, sigma_vo, sigma_vo_prime, Ic),\n            \n            # Other properties\n            'permeability': self.calculate_permeability(Ic, qt),\n            'unit_weight': self.calculate_unit_weight(qt, Ic)\n        }\n        \n        # Calculate Cr after Cc is known\n        parameters['recompression_index'] = self.calculate_recompression_index(\n            parameters['compression_index'], Ic=Ic\n        )\n        \n        return parameters\n    \n    def process_all_layers(self, layers_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Calculate parameters for all layers in a DataFrame.\n        \"\"\"\n        if len(layers_df) == 0:\n            return pd.DataFrame()\n        \n        results = []\n        for _, layer in layers_df.iterrows():\n            params = self.calculate_all_parameters(layer.to_dict())\n            results.append(params)\n        \n        return pd.DataFrame(results)\n","size_bytes":8999},"export_utils.py":{"content":"import pandas as pd\nimport numpy as np\nfrom fpdf import FPDF\nimport io\nfrom datetime import datetime\n\nclass PDFReport(FPDF):\n    \"\"\"\n    Custom PDF report generator for CPT analysis results.\n    \"\"\"\n    \n    def __init__(self, title=\"CPT Analysis Report\"):\n        super().__init__()\n        self.title_text = title\n        \n    def header(self):\n        self.set_font('Arial', 'B', 15)\n        self.cell(0, 10, self.title_text, 0, 1, 'C')\n        self.ln(5)\n    \n    def footer(self):\n        self.set_y(-15)\n        self.set_font('Arial', 'I', 8)\n        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n    \n    def chapter_title(self, title):\n        self.set_font('Arial', 'B', 12)\n        self.set_fill_color(200, 220, 255)\n        self.cell(0, 8, title, 0, 1, 'L', 1)\n        self.ln(2)\n    \n    def chapter_body(self, body):\n        self.set_font('Arial', '', 10)\n        self.multi_cell(0, 5, body)\n        self.ln()\n\n\nclass ExportManager:\n    \"\"\"\n    Manage export functionality for CPT analysis results.\n    \"\"\"\n    \n    @staticmethod\n    def export_to_excel(cpt_data: dict, layers_df: pd.DataFrame, \n                       params_df: pd.DataFrame, filename: str = \"cpt_analysis.xlsx\") -> io.BytesIO:\n        \"\"\"\n        Export all CPT data, layers, and parameters to Excel file.\n        \"\"\"\n        output = io.BytesIO()\n        \n        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n            if 'data' in cpt_data:\n                cpt_data['data'].to_excel(writer, sheet_name='CPT_Data', index=False)\n            \n            if len(layers_df) > 0:\n                layers_df.to_excel(writer, sheet_name='Soil_Layers', index=False)\n            \n            if len(params_df) > 0:\n                params_df.to_excel(writer, sheet_name='Parameters', index=False)\n        \n        output.seek(0)\n        return output\n    \n    @staticmethod\n    def export_settlement_results(settlement_results: dict, \n                                 params_df: pd.DataFrame,\n                                 load_config: dict) -> io.BytesIO:\n        \"\"\"\n        Export settlement calculation results to Excel.\n        \"\"\"\n        output = io.BytesIO()\n        \n        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n            summary_data = {\n                'Parameter': ['Applied Load (kN)', 'Footing Width (m)', 'Footing Length (m)',\n                            'Footing Depth (m)', 'Contact Pressure (kPa)',\n                            'Immediate Settlement (mm)', 'Consolidation Settlement (mm)',\n                            'Total Settlement (mm)'],\n                'Value': [\n                    load_config['load'],\n                    load_config['width'],\n                    load_config['length'],\n                    load_config['depth'],\n                    load_config['load'] / (load_config['width'] * load_config['length']),\n                    settlement_results['immediate_settlement_mm'],\n                    settlement_results['consolidation_settlement_mm'],\n                    settlement_results['total_settlement_mm']\n                ]\n            }\n            summary_df = pd.DataFrame(summary_data)\n            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n            \n            if 'immediate_details' in settlement_results:\n                imm_df = pd.DataFrame(settlement_results['immediate_details'])\n                imm_df.to_excel(writer, sheet_name='Immediate_Settlement', index=False)\n            \n            if 'consolidation_details' in settlement_results:\n                cons_df = pd.DataFrame(settlement_results['consolidation_details'])\n                cons_df.to_excel(writer, sheet_name='Consolidation_Settlement', index=False)\n            \n            if len(params_df) > 0:\n                params_df.to_excel(writer, sheet_name='Layer_Parameters', index=False)\n        \n        output.seek(0)\n        return output\n    \n    @staticmethod\n    def generate_pdf_report(cpt_name: str, summary: dict, layers_df: pd.DataFrame,\n                           params_df: pd.DataFrame, settlement_results: dict = None,\n                           load_config: dict = None) -> io.BytesIO:\n        \"\"\"\n        Generate comprehensive PDF report for CPT analysis.\n        \"\"\"\n        pdf = PDFReport(f\"CPT Analysis Report - {cpt_name}\")\n        pdf.add_page()\n        \n        pdf.set_font('Arial', '', 10)\n        pdf.cell(0, 5, f\"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", 0, 1)\n        pdf.ln(5)\n        \n        pdf.chapter_title(\"1. CPT Summary\")\n        summary_text = f\"\"\"\nCPT Name: {cpt_name}\nDepth Range: {summary['depth_range'][0]:.2f} - {summary['depth_range'][1]:.2f} m\nAverage qc: {summary['avg_qc']:.1f} kPa\nAverage Ic: {summary['avg_Ic']:.2f}\nPredominant Soil Type: {summary['predominant_soil']}\n        \"\"\"\n        pdf.chapter_body(summary_text.strip())\n        \n        pdf.chapter_title(\"2. Identified Soil Layers\")\n        if len(layers_df) > 0:\n            for idx, layer in layers_df.iterrows():\n                layer_text = f\"\"\"\nLayer {int(layer['layer_number'])}: {layer['soil_type']}\n  Depth: {layer['top_depth']:.2f} - {layer['bottom_depth']:.2f} m\n  Thickness: {layer['thickness']:.2f} m\n  Average Ic: {layer['avg_Ic']:.2f}\n  Average qc: {layer['avg_qc']:.1f} kPa\n                \"\"\"\n                pdf.chapter_body(layer_text.strip())\n        else:\n            pdf.chapter_body(\"No layers identified.\")\n        \n        pdf.add_page()\n        pdf.chapter_title(\"3. Soil Parameters from CPT Correlations\")\n        if len(params_df) > 0:\n            for idx, param in params_df.iterrows():\n                param_text = f\"\"\"\nLayer {int(param['layer_number'])}: {param['soil_type']}\n  Young's Modulus (E): {param['youngs_modulus']:.0f} kPa\n  Constrained Modulus (M): {param['constrained_modulus']:.0f} kPa\n  Compression Index (Cc): {param['compression_index']:.3f}\n  Recompression Index (Cr): {param['recompression_index']:.4f}\n  OCR: {param['OCR']:.2f}\n  Permeability (k): {param['permeability']:.2e} m/s\n                \"\"\"\n                if param['friction_angle'] > 0:\n                    param_text += f\"  Friction Angle: {param['friction_angle']:.1f} degrees\\n\"\n                if param['undrained_shear_strength'] > 0:\n                    param_text += f\"  Undrained Shear Strength: {param['undrained_shear_strength']:.1f} kPa\\n\"\n                \n                pdf.chapter_body(param_text.strip())\n        \n        if settlement_results is not None and load_config is not None:\n            pdf.add_page()\n            pdf.chapter_title(\"4. Settlement Analysis\")\n            \n            loading_text = f\"\"\"\nApplied Load: {load_config['load']:.1f} kN\nFooting Dimensions: {load_config['width']:.2f} m x {load_config['length']:.2f} m\nFooting Depth: {load_config['depth']:.2f} m\nContact Pressure: {load_config['load'] / (load_config['width'] * load_config['length']):.1f} kPa\n            \"\"\"\n            pdf.chapter_body(loading_text.strip())\n            \n            pdf.chapter_title(\"Settlement Results\")\n            results_text = f\"\"\"\nImmediate Settlement: {settlement_results['immediate_settlement_mm']:.1f} mm\nConsolidation Settlement: {settlement_results['consolidation_settlement_mm']:.1f} mm\nTotal Settlement: {settlement_results['total_settlement_mm']:.1f} mm\n            \"\"\"\n            pdf.chapter_body(results_text.strip())\n        \n        output = io.BytesIO()\n        pdf_output = pdf.output(dest='S')\n        # pdf_output is already bytes/bytearray, no need to encode\n        if isinstance(pdf_output, str):\n            output.write(pdf_output.encode('latin-1'))\n        else:\n            output.write(pdf_output)\n        output.seek(0)\n        \n        return output\n    \n    @staticmethod\n    def export_layers_to_csv(layers_df: pd.DataFrame) -> io.BytesIO:\n        \"\"\"\n        Export soil layers to CSV format.\n        \"\"\"\n        output = io.BytesIO()\n        layers_df.to_csv(output, index=False)\n        output.seek(0)\n        return output\n","size_bytes":7991},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"fpdf2>=2.8.5\",\n    \"matplotlib>=3.10.7\",\n    \"numpy>=2.3.4\",\n    \"openpyxl>=3.1.5\",\n    \"pandas>=2.3.3\",\n    \"pillow>=12.0.0\",\n    \"plotly>=6.3.1\",\n    \"scipy>=1.16.3\",\n    \"seaborn>=0.13.2\",\n    \"streamlit>=1.51.0\",\n]\n","size_bytes":366},"cpt_processor.py":{"content":"import pandas as pd\nimport numpy as np\nfrom typing import Dict, List, Tuple, Optional\n\nclass CPTProcessor:\n    \"\"\"\n    Process CPT (Cone Penetration Test) data including normalization and calculations.\n    Based on Robertson (2009) methodology.\n    \"\"\"\n    \n    def __init__(self):\n        self.Pa = 100.0  # Atmospheric pressure in kPa\n        self.gamma_water = 9.81  # Unit weight of water in kN/mÂ³\n    \n    def parse_text(self, file) -> pd.DataFrame:\n        \"\"\"\n        Parse text file (CSV, tab-delimited, or space-delimited) with flexible column detection.\n        Expected columns: Depth, qc (cone resistance), fs (sleeve friction), u2 (pore pressure)\n        Handles both files with headers and files without headers (assumes 4 columns: depth, qc, fs, u2)\n        \"\"\"\n        # Read the file content\n        content = file.read()\n        if isinstance(content, bytes):\n            content = content.decode('utf-8')\n        \n        # Try different delimiters\n        lines = content.strip().split('\\n')\n        if not lines:\n            raise ValueError(\"Empty text file\")\n        \n        # Detect delimiter by checking the first line\n        first_line = lines[0]\n        if '\\t' in first_line:\n            delimiter = '\\t'\n        elif ',' in first_line:\n            delimiter = ','\n        elif ';' in first_line:\n            delimiter = ';'\n        else:\n            delimiter = r'\\s+'  # Multiple spaces/whitespace\n        \n        # Check if first line contains text (header) or only numbers (no header)\n        from io import StringIO\n        first_values = first_line.split('\\t' if delimiter == '\\t' else ',' if delimiter == ',' else ';' if delimiter == ';' else None)\n        \n        # Try to determine if file has headers\n        has_header = False\n        try:\n            # If first value can't be converted to float, it's likely a header\n            float(first_values[0].strip())\n        except (ValueError, AttributeError):\n            has_header = True\n        \n        # Read with or without header\n        if has_header:\n            df = pd.read_csv(StringIO(content), sep=delimiter, engine='python')\n            # Clean column names\n            df.columns = df.columns.str.strip().str.lower()\n            \n            # Define possible column name variations\n            depth_keywords = ['depth', 'z', 'elevation', 'elev']\n            qc_keywords = ['qc', 'cone', 'resistance', 'tip resistance', 'qt']\n            fs_keywords = ['fs', 'sleeve', 'friction', 'sleeve friction']\n            u2_keywords = ['u2', 'u', 'pore', 'pore pressure', 'pwp']\n            \n            # Find matching columns\n            column_map = {}\n            for col in df.columns:\n                col_lower = str(col).lower()\n                if any(kw in col_lower for kw in depth_keywords) and 'depth' not in column_map:\n                    column_map['depth'] = col\n                elif any(kw in col_lower for kw in qc_keywords) and 'qc' not in column_map:\n                    column_map['qc'] = col\n                elif any(kw in col_lower for kw in fs_keywords) and 'fs' not in column_map:\n                    column_map['fs'] = col\n                elif any(kw in col_lower for kw in u2_keywords) and 'u2' not in column_map:\n                    column_map['u2'] = col\n            \n            # Check if essential columns are found\n            if 'depth' not in column_map or 'qc' not in column_map:\n                raise ValueError(\"Could not find 'depth' and 'qc' columns in the text file\")\n            \n            # Create standardized dataframe\n            result = pd.DataFrame()\n            result['depth'] = df[column_map['depth']].astype(float)\n            result['qc'] = df[column_map['qc']].astype(float)\n            \n            # Optional columns\n            if 'fs' in column_map:\n                result['fs'] = df[column_map['fs']].astype(float)\n            else:\n                result['fs'] = 0.0\n            \n            if 'u2' in column_map:\n                result['u2'] = df[column_map['u2']].astype(float)\n            else:\n                result['u2'] = 0.0\n        else:\n            # No header - assume columns are: depth, qc, fs, u2\n            df = pd.read_csv(StringIO(content), sep=delimiter, engine='python', header=None)\n            \n            # Assign default column names based on number of columns\n            result = pd.DataFrame()\n            if len(df.columns) >= 2:\n                result['depth'] = df[0].astype(float)\n                result['qc'] = df[1].astype(float)\n                result['fs'] = df[2].astype(float) if len(df.columns) > 2 else 0.0\n                result['u2'] = df[3].astype(float) if len(df.columns) > 3 else 0.0\n            else:\n                raise ValueError(\"Text file must have at least 2 columns (depth and qc)\")\n        \n        # Remove any rows with NaN values\n        result = result.dropna()\n        \n        return result\n    \n    def parse_excel(self, file, sheet_name: int = 0) -> pd.DataFrame:\n        \"\"\"\n        Parse Excel file with flexible column detection for CPT data.\n        Expected columns: Depth, qc (cone resistance), fs (sleeve friction), u2 (pore pressure)\n        \"\"\"\n        df = pd.read_excel(file, sheet_name=sheet_name)\n        \n        # Clean column names\n        df.columns = df.columns.str.strip().str.lower()\n        \n        # Define possible column name variations\n        depth_keywords = ['depth', 'z', 'elevation', 'elev']\n        qc_keywords = ['qc', 'cone', 'resistance', 'tip resistance', 'qt']\n        fs_keywords = ['fs', 'sleeve', 'friction', 'sleeve friction']\n        u2_keywords = ['u2', 'u', 'pore', 'pore pressure', 'pwp']\n        \n        # Find matching columns\n        column_map = {}\n        for col in df.columns:\n            col_lower = str(col).lower()\n            if any(kw in col_lower for kw in depth_keywords) and 'depth' not in column_map:\n                column_map['depth'] = col\n            elif any(kw in col_lower for kw in qc_keywords) and 'qc' not in column_map:\n                column_map['qc'] = col\n            elif any(kw in col_lower for kw in fs_keywords) and 'fs' not in column_map:\n                column_map['fs'] = col\n            elif any(kw in col_lower for kw in u2_keywords) and 'u2' not in column_map:\n                column_map['u2'] = col\n        \n        # Check if essential columns are found\n        if 'depth' not in column_map or 'qc' not in column_map:\n            raise ValueError(\"Could not find 'depth' and 'qc' columns in the Excel file\")\n        \n        # Create standardized dataframe\n        result = pd.DataFrame()\n        result['depth'] = df[column_map['depth']].astype(float)\n        result['qc'] = df[column_map['qc']].astype(float)\n        \n        # Optional columns\n        if 'fs' in column_map:\n            result['fs'] = df[column_map['fs']].astype(float)\n        else:\n            result['fs'] = 0.0  # Default if not provided\n        \n        if 'u2' in column_map:\n            result['u2'] = df[column_map['u2']].astype(float)\n        else:\n            result['u2'] = 0.0  # Default if not provided\n        \n        # Remove any rows with NaN values\n        result = result.dropna()\n        \n        return result\n    \n    def calculate_stresses(self, depth: np.ndarray, gamma_soil: float = 18.0, \n                          water_table_depth: float = 2.0) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Calculate total and effective overburden stresses.\n        \n        Parameters:\n        - depth: Array of depths in meters\n        - gamma_soil: Unit weight of soil in kN/mÂ³ (default 18)\n        - water_table_depth: Depth to water table in meters (default 2m)\n        \n        Returns:\n        - sigma_vo: Total overburden stress (kPa)\n        - sigma_vo_prime: Effective overburden stress (kPa)\n        \"\"\"\n        sigma_vo = gamma_soil * depth\n        \n        # Calculate pore pressure\n        u0 = np.where(depth > water_table_depth, \n                     self.gamma_water * (depth - water_table_depth), \n                     0)\n        \n        sigma_vo_prime = sigma_vo - u0\n        sigma_vo_prime = np.maximum(sigma_vo_prime, 1.0)  # Avoid division by zero\n        \n        return sigma_vo, sigma_vo_prime\n    \n    def calculate_normalized_parameters(self, df: pd.DataFrame, \n                                       gamma_soil: float = 18.0,\n                                       water_table_depth: float = 2.0,\n                                       area_ratio: float = 0.8) -> pd.DataFrame:\n        \"\"\"\n        Calculate normalized CPT parameters following Robertson (2009).\n        \n        Parameters:\n        - df: DataFrame with depth, qc, fs, u2\n        - gamma_soil: Unit weight of soil (kN/mÂ³)\n        - water_table_depth: Depth to water table (m)\n        - area_ratio: Net area ratio for cone (typically 0.7-0.9)\n        \"\"\"\n        result = df.copy()\n        \n        # Calculate stresses\n        sigma_vo, sigma_vo_prime = self.calculate_stresses(\n            result['depth'].values, gamma_soil, water_table_depth\n        )\n        \n        result['sigma_vo'] = sigma_vo\n        result['sigma_vo_prime'] = sigma_vo_prime\n        \n        # Calculate u0 (equilibrium pore pressure)\n        result['u0'] = np.where(result['depth'] > water_table_depth,\n                               self.gamma_water * (result['depth'] - water_table_depth),\n                               0)\n        \n        # Corrected cone resistance qt\n        result['qt'] = result['qc'] + result['u2'] * (1 - area_ratio)\n        \n        # Net cone resistance\n        result['qn'] = result['qt'] - sigma_vo\n        \n        # Normalized cone resistance (Qt1)\n        result['Qt1'] = (result['qt'] - sigma_vo) / sigma_vo_prime\n        \n        # Friction ratio (Rf in %)\n        result['Rf'] = (result['fs'] / result['qn']) * 100\n        result['Rf'] = result['Rf'].replace([np.inf, -np.inf], 0)\n        \n        # Normalized friction ratio (Fr in %)\n        result['Fr'] = (result['fs'] / (result['qt'] - sigma_vo)) * 100\n        result['Fr'] = result['Fr'].replace([np.inf, -np.inf], 0)\n        \n        # Pore pressure ratio (Bq)\n        result['Bq'] = (result['u2'] - result['u0']) / (result['qt'] - sigma_vo)\n        result['Bq'] = result['Bq'].replace([np.inf, -np.inf], 0)\n        \n        # Iterative calculation of Ic (Soil Behavior Type Index)\n        # Initial estimate with n = 1\n        n = 1.0\n        Qtn = ((result['qt'] - sigma_vo) / self.Pa) * (self.Pa / sigma_vo_prime)**n\n        \n        # Iterative refinement\n        for _ in range(5):  # Usually converges in 3-4 iterations\n            Qtn_log = np.log10(Qtn)\n            Fr_log = np.log10(result['Fr'] + 0.01)  # Avoid log(0)\n            \n            result['Ic'] = np.sqrt((3.47 - Qtn_log)**2 + (Fr_log + 1.22)**2)\n            \n            # Update n based on Ic\n            n = np.where(result['Ic'] > 2.6, 1.0, 0.5)\n            Qtn = ((result['qt'] - sigma_vo) / self.Pa) * (self.Pa / sigma_vo_prime)**n\n        \n        result['Qtn'] = Qtn\n        result['n_exponent'] = n\n        \n        return result\n    \n    def identify_soil_type(self, Ic: float) -> str:\n        \"\"\"\n        Identify soil behavior type based on Ic value (Robertson 2009).\n        \"\"\"\n        if Ic < 1.31:\n            return \"Gravelly sand to dense sand\"\n        elif Ic < 2.05:\n            return \"Sands: clean sand to silty sand\"\n        elif Ic < 2.60:\n            return \"Sand mixtures: silty sand to sandy silt\"\n        elif Ic < 2.95:\n            return \"Silt mixtures: clayey silt to silty clay\"\n        elif Ic < 3.60:\n            return \"Clays: silty clay to clay\"\n        else:\n            return \"Organic soils - clay\"\n    \n    def process_cpt_file(self, file, name: str, \n                        gamma_soil: float = 18.0,\n                        water_table_depth: float = 2.0) -> Dict:\n        \"\"\"\n        Complete processing of a CPT file.\n        \n        Returns a dictionary with:\n        - name: CPT name\n        - data: Processed DataFrame\n        - summary: Summary statistics\n        \"\"\"\n        # Parse the file based on file extension\n        file_name = file.name if hasattr(file, 'name') else name\n        if file_name.endswith('.txt') or file_name.endswith('.csv'):\n            df = self.parse_text(file)\n        else:\n            df = self.parse_excel(file)\n        \n        # Calculate normalized parameters\n        df = self.calculate_normalized_parameters(df, gamma_soil, water_table_depth)\n        \n        # Identify soil types\n        df['soil_type'] = df['Ic'].apply(self.identify_soil_type)\n        \n        # Generate summary\n        summary = {\n            'depth_range': (df['depth'].min(), df['depth'].max()),\n            'qc_range': (df['qc'].min(), df['qc'].max()),\n            'avg_qc': df['qc'].mean(),\n            'avg_Ic': df['Ic'].mean(),\n            'predominant_soil': df['soil_type'].mode()[0] if len(df) > 0 else \"Unknown\"\n        }\n        \n        return {\n            'name': name,\n            'data': df,\n            'summary': summary\n        }\n","size_bytes":13053},"app.py":{"content":"import streamlit as st\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport io\n\nfrom cpt_processor import CPTProcessor\nfrom soil_classification import (SoilLayering, RobertsonClassification, \n                                 Robertson1990Classification, Schneider2008Classification,\n                                 ClassificationComparator)\nfrom correlations import CPTCorrelations\nfrom settlement_calc import SettlementCalculator\nfrom export_utils import ExportManager\nfrom visualization_3d import CPT3DVisualizer\nfrom soil_database import SoilPropertyDatabase\n\nst.set_page_config(\n    page_title=\"CPT Analysis & Settlement Calculator\",\n    page_icon=\"ðŸ—ï¸\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\nst.title(\"ðŸ—ï¸ CPT Analysis & Settlement Calculator\")\nst.markdown(\"*Geotechnical analysis tool based on Settle3 correlations*\")\n\nif 'cpt_data' not in st.session_state:\n    st.session_state.cpt_data = {}\nif 'processed_cpts' not in st.session_state:\n    st.session_state.processed_cpts = {}\nif 'cpt_coordinates' not in st.session_state:\n    st.session_state.cpt_coordinates = {}\n\nwith st.sidebar:\n    st.header(\"âš™ï¸ Analysis Parameters\")\n    \n    st.subheader(\"Soil Properties\")\n    gamma_soil = st.number_input(\"Unit Weight of Soil (kN/mÂ³)\", \n                                 min_value=14.0, max_value=25.0, value=18.0, step=0.5)\n    water_table_depth = st.number_input(\"Water Table Depth (m)\", \n                                        min_value=0.0, max_value=50.0, value=2.0, step=0.5)\n    \n    st.subheader(\"Soil Layering\")\n    min_layer_thickness = st.number_input(\"Minimum Layer Thickness (m)\", \n                                         min_value=0.1, max_value=5.0, value=0.5, step=0.1)\n    \n    st.subheader(\"CPT Processing\")\n    area_ratio = st.number_input(\"Net Area Ratio\", \n                                 min_value=0.5, max_value=1.0, value=0.8, step=0.05)\n\ntab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([\n    \"ðŸ“¤ Upload CPT Data\", \n    \"ðŸ“Š CPT Profiles\", \n    \"ðŸ—ºï¸ Soil Classification\",\n    \"ðŸ“ Soil Layers\",\n    \"ðŸ“ˆ Correlations\",\n    \"ðŸ—ï¸ Settlement Analysis\",\n    \"ðŸŒ 3D Visualization\"\n])\n\nwith tab1:\n    st.header(\"Upload CPT Data Files\")\n    st.markdown(\"\"\"\n    Upload Excel or text files containing CPT data. The file should contain columns for:\n    - **Depth** (m)\n    - **qc** - Cone resistance (kPa or MPa)\n    - **fs** - Sleeve friction (kPa)\n    - **u2** - Pore pressure (kPa) [optional]\n    \n    **Supported formats:**\n    - Excel files (.xlsx, .xls)\n    - Text files (.txt, .csv) with comma, tab, semicolon, or space delimiters\n    \"\"\")\n    \n    uploaded_files = st.file_uploader(\n        \"Choose files\", \n        type=['xlsx', 'xls', 'txt', 'csv'],\n        accept_multiple_files=True,\n        key=\"cpt_upload\"\n    )\n    \n    if uploaded_files:\n        processor = CPTProcessor()\n        \n        for file in uploaded_files:\n            file_name = file.name.replace('.xlsx', '').replace('.xls', '').replace('.txt', '').replace('.csv', '')\n            \n            if file_name not in st.session_state.cpt_data:\n                try:\n                    with st.spinner(f\"Processing {file_name}...\"):\n                        result = processor.process_cpt_file(\n                            file, \n                            file_name, \n                            gamma_soil, \n                            water_table_depth\n                        )\n                        st.session_state.cpt_data[file_name] = result\n                        \n                        layering = SoilLayering(min_layer_thickness)\n                        layers = layering.process_layering(result['data'])\n                        \n                        correlator = CPTCorrelations()\n                        layer_params = correlator.process_all_layers(layers)\n                        \n                        st.session_state.processed_cpts[file_name] = {\n                            'data': result['data'],\n                            'layers': layers,\n                            'parameters': layer_params,\n                            'summary': result['summary']\n                        }\n                    \n                    st.success(f\"âœ… Successfully processed: {file_name}\")\n                except Exception as e:\n                    st.error(f\"âŒ Error processing {file_name}: {str(e)}\")\n        \n        if st.session_state.cpt_data:\n            st.subheader(\"Loaded CPT Files\")\n            for name, data in st.session_state.cpt_data.items():\n                summary = data['summary']\n                col1, col2, col3 = st.columns(3)\n                with col1:\n                    st.metric(\"CPT Name\", name)\n                with col2:\n                    st.metric(\"Depth Range\", f\"{summary['depth_range'][0]:.1f} - {summary['depth_range'][1]:.1f} m\")\n                with col3:\n                    st.metric(\"Predominant Soil\", summary['predominant_soil'])\n\nwith tab2:\n    st.header(\"CPT Profiles\")\n    \n    if not st.session_state.processed_cpts:\n        st.info(\"ðŸ“Œ Please upload CPT data files in the 'Upload CPT Data' tab first.\")\n    else:\n        selected_cpts = st.multiselect(\n            \"Select CPTs to display\",\n            options=list(st.session_state.processed_cpts.keys()),\n            default=list(st.session_state.processed_cpts.keys())\n        )\n        \n        if selected_cpts:\n            profile_type = st.selectbox(\n                \"Select Profile Type\",\n                [\"Cone Resistance (qc)\", \"Friction Ratio (Rf)\", \"Pore Pressure (u2)\", \n                 \"Normalized Parameters (Qt, Fr)\", \"Soil Behavior Index (Ic)\"]\n            )\n            \n            fig = make_subplots(\n                rows=1, cols=1,\n                subplot_titles=[profile_type]\n            )\n            \n            for cpt_name in selected_cpts:\n                data = st.session_state.processed_cpts[cpt_name]['data']\n                \n                if \"Cone Resistance\" in profile_type:\n                    fig.add_trace(go.Scatter(\n                        x=data['qc'], y=data['depth'],\n                        mode='lines', name=f\"{cpt_name} - qc\",\n                        line=dict(width=2)\n                    ))\n                    fig.update_xaxes(title_text=\"Cone Resistance qc (kPa)\")\n                \n                elif \"Friction Ratio\" in profile_type:\n                    fig.add_trace(go.Scatter(\n                        x=data['Rf'], y=data['depth'],\n                        mode='lines', name=f\"{cpt_name} - Rf\",\n                        line=dict(width=2)\n                    ))\n                    fig.update_xaxes(title_text=\"Friction Ratio Rf (%)\")\n                \n                elif \"Pore Pressure\" in profile_type:\n                    fig.add_trace(go.Scatter(\n                        x=data['u2'], y=data['depth'],\n                        mode='lines', name=f\"{cpt_name} - u2\",\n                        line=dict(width=2)\n                    ))\n                    fig.update_xaxes(title_text=\"Pore Pressure u2 (kPa)\")\n                \n                elif \"Normalized\" in profile_type:\n                    fig.add_trace(go.Scatter(\n                        x=data['Qt1'], y=data['depth'],\n                        mode='lines', name=f\"{cpt_name} - Qt\",\n                        line=dict(width=2)\n                    ))\n                    fig.update_xaxes(title_text=\"Normalized Cone Resistance Qt\", type='log')\n                \n                elif \"Soil Behavior\" in profile_type:\n                    fig.add_trace(go.Scatter(\n                        x=data['Ic'], y=data['depth'],\n                        mode='lines', name=f\"{cpt_name} - Ic\",\n                        line=dict(width=2)\n                    ))\n                    fig.update_xaxes(title_text=\"Soil Behavior Type Index Ic\")\n            \n            fig.update_yaxes(title_text=\"Depth (m)\", autorange=\"reversed\")\n            fig.update_layout(height=600, hovermode='closest')\n            \n            st.plotly_chart(fig, use_container_width=True)\n            \n            if len(st.session_state.processed_cpts) > 1:\n                st.markdown(\"---\")\n                st.subheader(\"ðŸ“Š Multi-CPT Comparison & Batch Export\")\n                \n                comparison_data = []\n                for cpt_name, cpt_info in st.session_state.processed_cpts.items():\n                    summary = cpt_info['summary']\n                    layers = cpt_info['layers']\n                    params = cpt_info['parameters']\n                    \n                    comparison_data.append({\n                        'CPT Name': cpt_name,\n                        'Max Depth (m)': summary['depth_range'][1],\n                        'Avg qc (kPa)': summary['avg_qc'],\n                        'Avg Ic': summary['avg_Ic'],\n                        'Number of Layers': len(layers),\n                        'Dominant Soil': summary['predominant_soil'],\n                        'Avg E (kPa)': params['youngs_modulus'].mean() if len(params) > 0 else 0,\n                        'Avg OCR': params['OCR'].mean() if len(params) > 0 else 0\n                    })\n                \n                comparison_df = pd.DataFrame(comparison_data)\n                st.dataframe(comparison_df.round(2), hide_index=True, use_container_width=True)\n                \n                col_batch1, col_batch2 = st.columns(2)\n                \n                with col_batch1:\n                    st.markdown(\"**Batch Export Options**\")\n                    if st.button(\"ðŸ“¦ Generate Batch Report\", key=\"batch_report\"):\n                        with st.spinner(\"Generating batch report for all CPTs...\"):\n                            # Create a combined Excel workbook with all CPTs\n                            exporter = ExportManager()\n                            output = io.BytesIO()\n                            \n                            with pd.ExcelWriter(output, engine='openpyxl') as writer:\n                                # Summary sheet\n                                comparison_df.to_excel(writer, sheet_name='Summary', index=False)\n                                \n                                # Individual CPT sheets\n                                for cpt_name, cpt_info in st.session_state.processed_cpts.items():\n                                    # Truncate sheet name to 31 chars (Excel limit)\n                                    sheet_name = cpt_name[:28] + \"...\" if len(cpt_name) > 31 else cpt_name\n                                    \n                                    layers = cpt_info['layers']\n                                    params = cpt_info['parameters']\n                                    \n                                    # Combine layers and params\n                                    combined = pd.merge(\n                                        layers[['layer_number', 'soil_type', 'top_depth', 'bottom_depth', 'thickness']],\n                                        params[['layer_number', 'youngs_modulus', 'compression_index', 'OCR']],\n                                        on='layer_number',\n                                        how='left'\n                                    )\n                                    \n                                    combined.to_excel(writer, sheet_name=sheet_name, index=False)\n                            \n                            output.seek(0)\n                            st.session_state['batch_report'] = output.getvalue()\n                            st.success(\"âœ… Batch report generated!\")\n                \n                with col_batch2:\n                    if 'batch_report' in st.session_state:\n                        st.markdown(\"**Download Batch Report**\")\n                        st.download_button(\n                            label=\"ðŸ“¥ Download All CPTs (Excel)\",\n                            data=st.session_state['batch_report'],\n                            file_name=\"batch_cpt_analysis.xlsx\",\n                            mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\",\n                            key=\"download_batch\"\n                        )\n                        st.info(f\"ðŸ“Š Report includes {len(st.session_state.processed_cpts)} CPT datasets\")\n\nwith tab3:\n    st.header(\"CPT Soil Classification Methods\")\n    \n    if not st.session_state.processed_cpts:\n        st.info(\"ðŸ“Œ Please upload CPT data files in the 'Upload CPT Data' tab first.\")\n    else:\n        col1, col2 = st.columns([2, 1])\n        \n        with col1:\n            selected_cpt = st.selectbox(\n                \"Select CPT for classification\",\n                options=list(st.session_state.processed_cpts.keys())\n            )\n        \n        with col2:\n            classification_method = st.selectbox(\n                \"Classification Method\",\n                options=[\"Robertson 2009\", \"Robertson 1990\", \"Schneider 2008\", \"Method Comparison\"]\n            )\n        \n        if selected_cpt:\n            data = st.session_state.processed_cpts[selected_cpt]['data']\n            \n            if classification_method == \"Robertson 2009\":\n                st.subheader(\"Robertson (2009) Classification Chart\")\n                st.markdown(\"*Latest CPT soil behavior type classification*\")\n                \n                fig = go.Figure()\n                \n                Qt_range = (1, 1000)\n                classification = RobertsonClassification()\n                contours = classification.calculate_Ic_contours(Qt_range)\n                \n                for Ic_value, contour_data in contours.items():\n                    fig.add_trace(go.Scatter(\n                        x=contour_data[:, 0],\n                        y=contour_data[:, 1],\n                        mode='lines',\n                        name=f'Ic = {Ic_value}',\n                        line=dict(color='gray', dash='dash', width=1),\n                        showlegend=True\n                    ))\n                \n                fig.add_trace(go.Scatter(\n                    x=data['Qt1'],\n                    y=data['Fr'],\n                    mode='markers',\n                    name=selected_cpt,\n                    marker=dict(\n                        size=6,\n                        color=data['Ic'],\n                        colorscale='RdYlBu_r',\n                        showscale=True,\n                        colorbar=dict(title=\"Ic\"),\n                        line=dict(width=0.5, color='white')\n                    ),\n                    text=data['depth'],\n                    hovertemplate='<b>Depth: %{text:.1f} m</b><br>Qt: %{x:.1f}<br>Fr: %{y:.2f}%<extra></extra>'\n                ))\n                \n                fig.update_xaxes(title_text=\"Normalized Cone Resistance Qt\", type='log', range=[0, 3])\n                fig.update_yaxes(title_text=\"Normalized Friction Ratio Fr (%)\", type='log', range=[-1, 1])\n                fig.update_layout(\n                    height=600,\n                    title=f\"Robertson (2009) Classification Chart - {selected_cpt}\",\n                    hovermode='closest'\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n                \n                st.subheader(\"Soil Type Distribution\")\n                soil_type_counts = data['soil_type'].value_counts()\n                \n                fig_pie = go.Figure(data=[go.Pie(\n                    labels=soil_type_counts.index,\n                    values=soil_type_counts.values,\n                    hole=0.3\n                )])\n                fig_pie.update_layout(height=400)\n                st.plotly_chart(fig_pie, use_container_width=True)\n            \n            elif classification_method == \"Robertson 1990\":\n                st.subheader(\"Robertson (1990) Classification Chart\")\n                st.markdown(\"*Normalized CPT soil behavior type with 9 zones*\")\n                \n                # Calculate Robertson 1990 classifications\n                data_r1990 = data.copy()\n                data_r1990['soil_type_r1990'] = data_r1990.apply(\n                    lambda row: Robertson1990Classification.classify_soil_type(\n                        row['Qt1'], row['Fr'], row['Ic']\n                    ), axis=1\n                )\n                \n                fig = go.Figure()\n                \n                Qt_range = (1, 1000)\n                contours = Robertson1990Classification.calculate_Ic_contours(Qt_range)\n                \n                for Ic_value, contour_data in contours.items():\n                    fig.add_trace(go.Scatter(\n                        x=contour_data[:, 0],\n                        y=contour_data[:, 1],\n                        mode='lines',\n                        name=f'Ic = {Ic_value}',\n                        line=dict(color='gray', dash='dash', width=1),\n                        showlegend=True\n                    ))\n                \n                fig.add_trace(go.Scatter(\n                    x=data_r1990['Qt1'],\n                    y=data_r1990['Fr'],\n                    mode='markers',\n                    name=selected_cpt,\n                    marker=dict(\n                        size=6,\n                        color=data_r1990['Ic'],\n                        colorscale='Viridis',\n                        showscale=True,\n                        colorbar=dict(title=\"Ic\"),\n                        line=dict(width=0.5, color='white')\n                    ),\n                    text=data_r1990['depth'],\n                    hovertemplate='<b>Depth: %{text:.1f} m</b><br>Qt: %{x:.1f}<br>Fr: %{y:.2f}%<extra></extra>'\n                ))\n                \n                fig.update_xaxes(title_text=\"Normalized Cone Resistance Qt\", type='log', range=[0, 3])\n                fig.update_yaxes(title_text=\"Normalized Friction Ratio Fr (%)\", type='log', range=[-1, 1])\n                fig.update_layout(\n                    height=600,\n                    title=f\"Robertson (1990) Classification Chart - {selected_cpt}\",\n                    hovermode='closest'\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n                \n                st.subheader(\"Soil Type Distribution\")\n                soil_type_counts = data_r1990['soil_type_r1990'].value_counts()\n                \n                fig_pie = go.Figure(data=[go.Pie(\n                    labels=soil_type_counts.index,\n                    values=soil_type_counts.values,\n                    hole=0.3\n                )])\n                fig_pie.update_layout(height=400)\n                st.plotly_chart(fig_pie, use_container_width=True)\n            \n            elif classification_method == \"Schneider 2008\":\n                st.subheader(\"Schneider et al. (2008) Classification Chart\")\n                st.markdown(\"*Piezocone classification focusing on drainage conditions*\")\n                \n                # Calculate Schneider 2008 classifications\n                data_s2008 = data.copy()\n                data_s2008['soil_type_s2008'] = data_s2008.apply(\n                    lambda row: Schneider2008Classification.classify_soil_type(\n                        row['Qt1'], row['Fr']\n                    ), axis=1\n                )\n                \n                fig = go.Figure()\n                \n                # Add zone boundaries\n                boundaries = Schneider2008Classification.calculate_zone_boundaries()\n                \n                for boundary_name, boundary_data in boundaries.items():\n                    fig.add_trace(go.Scatter(\n                        x=boundary_data[:, 0],\n                        y=boundary_data[:, 1],\n                        mode='lines',\n                        name=boundary_name.replace('_', ' ').title(),\n                        line=dict(color='black', dash='dash', width=2),\n                        showlegend=True\n                    ))\n                \n                # Add data points\n                fig.add_trace(go.Scatter(\n                    x=data_s2008['Qt1'],\n                    y=data_s2008['Fr'],\n                    mode='markers',\n                    name=selected_cpt,\n                    marker=dict(\n                        size=6,\n                        color=data_s2008['Ic'],\n                        colorscale='Plasma',\n                        showscale=True,\n                        colorbar=dict(title=\"Ic\"),\n                        line=dict(width=0.5, color='white')\n                    ),\n                    text=data_s2008['depth'],\n                    hovertemplate='<b>Depth: %{text:.1f} m</b><br>Q: %{x:.1f}<br>F: %{y:.2f}%<extra></extra>'\n                ))\n                \n                fig.update_xaxes(title_text=\"Normalized Cone Resistance Q\", type='log', range=[0, 3])\n                fig.update_yaxes(title_text=\"Friction Ratio F (%)\", type='log', range=[-1, 1])\n                fig.update_layout(\n                    height=600,\n                    title=f\"Schneider (2008) Q-F Classification Chart - {selected_cpt}\",\n                    hovermode='closest'\n                )\n                \n                st.plotly_chart(fig, use_container_width=True)\n                \n                st.subheader(\"Soil Type Distribution\")\n                soil_type_counts = data_s2008['soil_type_s2008'].value_counts()\n                \n                fig_pie = go.Figure(data=[go.Pie(\n                    labels=soil_type_counts.index,\n                    values=soil_type_counts.values,\n                    hole=0.3\n                )])\n                fig_pie.update_layout(height=400)\n                st.plotly_chart(fig_pie, use_container_width=True)\n            \n            elif classification_method == \"Method Comparison\":\n                st.subheader(\"Classification Method Comparison\")\n                st.markdown(\"*Compare soil classifications from different methods*\")\n                \n                col_comp1, col_comp2 = st.columns(2)\n                \n                with col_comp1:\n                    method1 = st.selectbox(\n                        \"Method 1\",\n                        options=[\"Robertson2009\", \"Robertson1990\", \"Schneider2008\"],\n                        key=\"method1_select\"\n                    )\n                \n                with col_comp2:\n                    method2 = st.selectbox(\n                        \"Method 2\",\n                        options=[\"Robertson2009\", \"Robertson1990\", \"Schneider2008\"],\n                        key=\"method2_select\",\n                        index=1\n                    )\n                \n                # Perform comparison\n                comparator = ClassificationComparator()\n                comparison_data = comparator.compare_classifications(data, method1, method2)\n                stats = comparator.get_agreement_statistics(comparison_data)\n                \n                # Display statistics\n                col_stat1, col_stat2, col_stat3 = st.columns(3)\n                \n                with col_stat1:\n                    st.metric(\"Total Points\", stats['total_points'])\n                with col_stat2:\n                    st.metric(\"Agreed Points\", stats['agreed_points'])\n                with col_stat3:\n                    st.metric(\"Agreement %\", f\"{stats['agreement_percentage']:.1f}%\")\n                \n                # Visualization\n                fig_comp = go.Figure()\n                \n                # Color code by agreement\n                colors = ['green' if agree else 'red' for agree in comparison_data['agreement']]\n                \n                fig_comp.add_trace(go.Scatter(\n                    x=comparison_data['Qt1'],\n                    y=comparison_data['Fr'],\n                    mode='markers',\n                    marker=dict(\n                        size=6,\n                        color=colors,\n                        line=dict(width=0.5, color='white')\n                    ),\n                    text=[f\"Depth: {d:.1f}m<br>{method1}: {s1}<br>{method2}: {s2}\" \n                          for d, s1, s2 in zip(comparison_data['depth'], \n                                               comparison_data['method1_soil_type'],\n                                               comparison_data['method2_soil_type'])],\n                    hovertemplate='%{text}<extra></extra>',\n                    name='CPT Data'\n                ))\n                \n                fig_comp.update_xaxes(title_text=\"Normalized Cone Resistance Qt\", type='log', range=[0, 3])\n                fig_comp.update_yaxes(title_text=\"Normalized Friction Ratio Fr (%)\", type='log', range=[-1, 1])\n                fig_comp.update_layout(\n                    height=600,\n                    title=f\"Comparison: {method1} vs {method2}<br>Green=Agree, Red=Disagree\",\n                    hovermode='closest'\n                )\n                \n                st.plotly_chart(fig_comp, use_container_width=True)\n                \n                # Disagreement table\n                st.subheader(\"Points of Disagreement\")\n                disagreed = comparison_data[~comparison_data['agreement']][['depth', 'Qt1', 'Fr', 'Ic', \n                                                                             'method1_soil_type', 'method2_soil_type']].copy()\n                disagreed = disagreed.rename(columns={\n                    'depth': 'Depth (m)',\n                    'Qt1': 'Qt',\n                    'Fr': 'Fr (%)',\n                    'Ic': 'Ic',\n                    'method1_soil_type': method1,\n                    'method2_soil_type': method2\n                })\n                \n                if len(disagreed) > 0:\n                    st.dataframe(disagreed.round(2), hide_index=True, use_container_width=True)\n                else:\n                    st.success(\"âœ… All classifications agree between the two methods!\")\n\nwith tab4:\n    st.header(\"Identified Soil Layers\")\n    \n    if not st.session_state.processed_cpts:\n        st.info(\"ðŸ“Œ Please upload CPT data files in the 'Upload CPT Data' tab first.\")\n    else:\n        selected_cpt = st.selectbox(\n            \"Select CPT for layer profile\",\n            options=list(st.session_state.processed_cpts.keys()),\n            key=\"layer_select\"\n        )\n        \n        if selected_cpt:\n            layers = st.session_state.processed_cpts[selected_cpt]['layers']\n            \n            if len(layers) > 0:\n                col1, col2 = st.columns([2, 1])\n                \n                with col1:\n                    fig = go.Figure()\n                    \n                    for _, layer in layers.iterrows():\n                        mid_depth = (layer['top_depth'] + layer['bottom_depth']) / 2\n                        \n                        fig.add_trace(go.Bar(\n                            x=[layer['thickness']],\n                            y=[f\"Layer {layer['layer_number']}\"],\n                            orientation='h',\n                            name=layer['soil_type'],\n                            text=f\"{layer['soil_type']}<br>{layer['thickness']:.2f}m\",\n                            textposition='inside',\n                            hovertemplate=f\"<b>Layer {layer['layer_number']}</b><br>\" +\n                                        f\"Depth: {layer['top_depth']:.2f} - {layer['bottom_depth']:.2f} m<br>\" +\n                                        f\"Thickness: {layer['thickness']:.2f} m<br>\" +\n                                        f\"Soil: {layer['soil_type']}<br>\" +\n                                        f\"Ic: {layer['avg_Ic']:.2f}<extra></extra>\"\n                        ))\n                    \n                    fig.update_xaxes(title_text=\"Thickness (m)\")\n                    fig.update_yaxes(title_text=\"Layer\")\n                    fig.update_layout(\n                        height=max(400, len(layers) * 50),\n                        showlegend=False,\n                        title=f\"Soil Layer Profile - {selected_cpt}\"\n                    )\n                    \n                    st.plotly_chart(fig, use_container_width=True)\n                \n                with col2:\n                    st.subheader(\"Layer Summary\")\n                    st.dataframe(\n                        layers[['layer_number', 'top_depth', 'bottom_depth', \n                               'thickness', 'soil_type', 'avg_Ic']].round(2),\n                        hide_index=True,\n                        height=400\n                    )\n                    \n                    st.subheader(\"Export Layers\")\n                    exporter = ExportManager()\n                    csv_data = exporter.export_layers_to_csv(layers)\n                    st.download_button(\n                        label=\"ðŸ“¥ Download Layers (CSV)\",\n                        data=csv_data,\n                        file_name=f\"{selected_cpt}_layers.csv\",\n                        mime=\"text/csv\"\n                    )\n            else:\n                st.warning(\"No layers identified for this CPT.\")\n\nwith tab5:\n    st.header(\"CPT Correlations for Settlement Parameters\")\n    \n    if not st.session_state.processed_cpts:\n        st.info(\"ðŸ“Œ Please upload CPT data files in the 'Upload CPT Data' tab first.\")\n    else:\n        selected_cpt = st.selectbox(\n            \"Select CPT for correlations\",\n            options=list(st.session_state.processed_cpts.keys()),\n            key=\"corr_select\"\n        )\n        \n        if selected_cpt:\n            params = st.session_state.processed_cpts[selected_cpt]['parameters']\n            \n            if len(params) > 0:\n                st.subheader(\"Settlement Parameters by Layer\")\n                \n                display_params = params[[\n                    'layer_number', 'soil_type', 'thickness', 'Ic',\n                    'youngs_modulus', 'constrained_modulus',\n                    'compression_index', 'recompression_index',\n                    'OCR', 'friction_angle', 'undrained_shear_strength'\n                ]].copy()\n                \n                display_params.columns = [\n                    'Layer', 'Soil Type', 'H (m)', 'Ic',\n                    'E (kPa)', 'M (kPa)', 'Cc', 'Cr',\n                    'OCR', 'Ï† (Â°)', 'Su (kPa)'\n                ]\n                \n                st.dataframe(display_params.round(2), hide_index=True, use_container_width=True)\n                \n                st.subheader(\"Parameter Visualizations\")\n                \n                param_cols = st.columns(2)\n                \n                with param_cols[0]:\n                    fig_e = go.Figure()\n                    fig_e.add_trace(go.Bar(\n                        x=params['layer_number'],\n                        y=params['youngs_modulus'],\n                        name=\"Young's Modulus\",\n                        marker_color='lightblue'\n                    ))\n                    fig_e.update_layout(\n                        title=\"Young's Modulus (E) by Layer\",\n                        xaxis_title=\"Layer Number\",\n                        yaxis_title=\"E (kPa)\",\n                        height=300\n                    )\n                    st.plotly_chart(fig_e, use_container_width=True)\n                \n                with param_cols[1]:\n                    fig_cc = go.Figure()\n                    clay_layers = params[params['Ic'] > 2.6]\n                    if len(clay_layers) > 0:\n                        fig_cc.add_trace(go.Bar(\n                            x=clay_layers['layer_number'],\n                            y=clay_layers['compression_index'],\n                            name=\"Cc\",\n                            marker_color='coral'\n                        ))\n                        fig_cc.add_trace(go.Bar(\n                            x=clay_layers['layer_number'],\n                            y=clay_layers['recompression_index'],\n                            name=\"Cr\",\n                            marker_color='lightcoral'\n                        ))\n                    fig_cc.update_layout(\n                        title=\"Compression Indices (Cc, Cr) for Clay Layers\",\n                        xaxis_title=\"Layer Number\",\n                        yaxis_title=\"Index\",\n                        height=300\n                    )\n                    st.plotly_chart(fig_cc, use_container_width=True)\n                \n                param_cols2 = st.columns(2)\n                \n                with param_cols2[0]:\n                    fig_ocr = go.Figure()\n                    fig_ocr.add_trace(go.Bar(\n                        x=params['layer_number'],\n                        y=params['OCR'],\n                        name=\"OCR\",\n                        marker_color='lightgreen'\n                    ))\n                    fig_ocr.update_layout(\n                        title=\"Over-Consolidation Ratio (OCR) by Layer\",\n                        xaxis_title=\"Layer Number\",\n                        yaxis_title=\"OCR\",\n                        height=300\n                    )\n                    st.plotly_chart(fig_ocr, use_container_width=True)\n                \n                with param_cols2[1]:\n                    fig_perm = go.Figure()\n                    fig_perm.add_trace(go.Bar(\n                        x=params['layer_number'],\n                        y=params['permeability'],\n                        name=\"Permeability\",\n                        marker_color='purple'\n                    ))\n                    fig_perm.update_layout(\n                        title=\"Permeability (k) by Layer\",\n                        xaxis_title=\"Layer Number\",\n                        yaxis_title=\"k (m/s)\",\n                        yaxis_type=\"log\",\n                        height=300\n                    )\n                    st.plotly_chart(fig_perm, use_container_width=True)\n                \n                st.subheader(\"Export Data\")\n                exporter = ExportManager()\n                layers = st.session_state.processed_cpts[selected_cpt]['layers']\n                excel_data = exporter.export_to_excel(\n                    st.session_state.processed_cpts[selected_cpt],\n                    layers,\n                    params,\n                    f\"{selected_cpt}_analysis.xlsx\"\n                )\n                st.download_button(\n                    label=\"ðŸ“¥ Download Complete Analysis (Excel)\",\n                    data=excel_data,\n                    file_name=f\"{selected_cpt}_analysis.xlsx\",\n                    mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n                )\n                \n                st.markdown(\"---\")\n                \n                st.subheader(\"ðŸ“š Soil Property Database & Validation\")\n                \n                soil_db = SoilPropertyDatabase()\n                \n                tab_db1, tab_db2 = st.tabs([\"Parameter Validation\", \"Reference Database\"])\n                \n                with tab_db1:\n                    st.markdown(\"*Compare calculated parameters against typical ranges for soil types*\")\n                    \n                    warnings = soil_db.compare_layer_properties(params)\n                    \n                    if len(warnings) > 0:\n                        st.warning(f\"âš ï¸ Found {len(warnings)} parameter(s) outside typical ranges:\")\n                        \n                        warning_df = pd.DataFrame(warnings)\n                        warning_df.columns = ['Layer', 'Soil Type', 'Parameter', 'Value', 'Message']\n                        st.dataframe(warning_df, hide_index=True, use_container_width=True)\n                        \n                        st.info(\"ðŸ’¡ These warnings indicate parameters that fall outside typical literature ranges. Review correlations and site conditions.\")\n                    else:\n                        st.success(\"âœ… All calculated parameters are within typical ranges for their soil types!\")\n                \n                with tab_db2:\n                    st.markdown(\"*Reference ranges for typical soil types from geotechnical literature*\")\n                    \n                    db_summary = soil_db.get_database_summary()\n                    st.dataframe(db_summary, hide_index=True, use_container_width=True)\n                    \n                    st.info(\"ðŸ’¡ Reference ranges based on geotechnical engineering standards and literature. Actual site conditions may vary.\")\n            else:\n                st.warning(\"No parameters calculated for this CPT.\")\n\nwith tab6:\n    st.header(\"Settlement Analysis\")\n    \n    if not st.session_state.processed_cpts:\n        st.info(\"ðŸ“Œ Please upload CPT data files in the 'Upload CPT Data' tab first.\")\n    else:\n        st.subheader(\"Loading Configuration\")\n        \n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            load_kN = st.number_input(\"Applied Load (kN)\", min_value=0.0, value=1000.0, step=100.0)\n            footing_width = st.number_input(\"Footing Width (m)\", min_value=0.1, value=2.0, step=0.1)\n        \n        with col2:\n            footing_length = st.number_input(\"Footing Length (m)\", min_value=0.1, value=2.0, step=0.1)\n            footing_depth = st.number_input(\"Footing Depth (m)\", min_value=0.0, value=1.0, step=0.1)\n        \n        with col3:\n            st.metric(\"Contact Pressure\", f\"{load_kN / (footing_width * footing_length):.1f} kPa\")\n            st.metric(\"Water Table Depth\", f\"{water_table_depth:.1f} m\")\n        \n        selected_cpt_settle = st.selectbox(\n            \"Select CPT for settlement analysis\",\n            options=list(st.session_state.processed_cpts.keys()),\n            key=\"settle_select\"\n        )\n        \n        if selected_cpt_settle and st.button(\"Calculate Settlement\", type=\"primary\"):\n            params = st.session_state.processed_cpts[selected_cpt_settle]['parameters']\n            \n            calculator = SettlementCalculator()\n            \n            settlement_results = calculator.calculate_total_settlement(\n                params, load_kN, footing_width, footing_length,\n                footing_depth, water_table_depth\n            )\n            \n            # Store in session state\n            st.session_state['settlement_results'] = settlement_results\n            st.session_state['settlement_params'] = {\n                'load': load_kN,\n                'width': footing_width,\n                'length': footing_length,\n                'depth': footing_depth,\n                'water_table': water_table_depth,\n                'cpt_name': selected_cpt_settle\n            }\n            st.session_state['settlement_calculator'] = calculator\n            \n            st.success(\"âœ… Settlement calculation complete!\")\n        \n        # Display results if they exist in session state\n        if 'settlement_results' in st.session_state:\n            settlement_results = st.session_state['settlement_results']\n            settlement_params_stored = st.session_state.get('settlement_params', {})\n            \n            col1, col2, col3 = st.columns(3)\n            with col1:\n                st.metric(\"Immediate Settlement\", f\"{settlement_results['immediate_settlement_mm']:.1f} mm\")\n            with col2:\n                st.metric(\"Consolidation Settlement\", f\"{settlement_results['consolidation_settlement_mm']:.1f} mm\")\n            with col3:\n                st.metric(\"Total Settlement\", f\"{settlement_results['total_settlement_mm']:.1f} mm\", \n                         delta=f\"{settlement_results['total_settlement_mm']:.1f} mm\")\n            \n            st.subheader(\"Settlement by Layer\")\n            \n            immediate_df = pd.DataFrame(settlement_results['immediate_details'])\n            consolidation_df = pd.DataFrame(settlement_results['consolidation_details'])\n            \n            tabs_settle = st.tabs([\"Immediate Settlement\", \"Consolidation Settlement\"])\n            \n            with tabs_settle[0]:\n                st.dataframe(immediate_df.round(2), hide_index=True, use_container_width=True)\n                \n                fig_imm = go.Figure()\n                fig_imm.add_trace(go.Bar(\n                    x=immediate_df['layer_number'],\n                    y=immediate_df['settlement_mm'],\n                    marker_color='skyblue',\n                    text=immediate_df['settlement_mm'].round(1),\n                    textposition='outside'\n                ))\n                fig_imm.update_layout(\n                    title=\"Immediate Settlement by Layer\",\n                    xaxis_title=\"Layer Number\",\n                    yaxis_title=\"Settlement (mm)\",\n                    height=400\n                )\n                st.plotly_chart(fig_imm, use_container_width=True)\n            \n            with tabs_settle[1]:\n                st.dataframe(consolidation_df.round(2), hide_index=True, use_container_width=True)\n                \n                fig_cons = go.Figure()\n                fig_cons.add_trace(go.Bar(\n                    x=consolidation_df['layer_number'],\n                    y=consolidation_df['settlement_mm'],\n                    marker_color='coral',\n                    text=consolidation_df['settlement_mm'].round(1),\n                    textposition='outside'\n                ))\n                fig_cons.update_layout(\n                    title=\"Consolidation Settlement by Layer\",\n                    xaxis_title=\"Layer Number\",\n                    yaxis_title=\"Settlement (mm)\",\n                    height=400\n                )\n                st.plotly_chart(fig_cons, use_container_width=True)\n            \n            st.markdown(\"---\")\n            \n            st.subheader(\"â±ï¸ Time-Consolidation Analysis\")\n            st.markdown(\"*Analyze settlement progression over time including secondary compression (creep)*\")\n            \n            col_time1, col_time2, col_time3 = st.columns(3)\n            \n            with col_time1:\n                max_time = st.number_input(\n                    \"Maximum Time (years)\",\n                    min_value=1.0,\n                    max_value=100.0,\n                    value=50.0,\n                    step=5.0,\n                    help=\"Time period for consolidation analysis\"\n                )\n            \n            with col_time2:\n                include_secondary = st.checkbox(\n                    \"Include Secondary Compression\",\n                    value=True,\n                    help=\"Add long-term creep effects\"\n                )\n            \n            with col_time3:\n                c_alpha_ratio = st.number_input(\n                    \"C_Î±/Cc Ratio\",\n                    min_value=0.01,\n                    max_value=0.10,\n                    value=0.02,\n                    step=0.01,\n                    help=\"Secondary compression index ratio (typical 0.02-0.05)\"\n                )\n            \n            if st.button(\"Generate Time-Settlement Curve\", key=\"time_curve_btn\"):\n                with st.spinner(\"Calculating time-dependent settlement...\"):\n                    # Get stored calculator and params\n                    calculator_stored = st.session_state.get('settlement_calculator', SettlementCalculator())\n                    cpt_name_stored = settlement_params_stored.get('cpt_name', selected_cpt_settle)\n                    params_stored = st.session_state.processed_cpts[cpt_name_stored]['parameters']\n                    \n                    time_curve_data = calculator_stored.generate_time_settlement_curve(\n                        params_stored, \n                        settlement_params_stored.get('load', load_kN), \n                        settlement_params_stored.get('width', footing_width), \n                        settlement_params_stored.get('length', footing_length),\n                        max_time_years=max_time,\n                        num_points=100,\n                        footing_depth=settlement_params_stored.get('depth', footing_depth),\n                        water_table_depth=settlement_params_stored.get('water_table', water_table_depth),\n                        include_secondary=include_secondary,\n                        c_alpha=c_alpha_ratio\n                    )\n                    \n                    # Store in session state for persistence\n                    st.session_state['time_curve_data'] = time_curve_data\n                    st.success(\"âœ… Time-consolidation curve generated!\")\n            \n            if 'time_curve_data' in st.session_state:\n                time_curve_data = st.session_state['time_curve_data']\n                \n                # Main time-settlement curve\n                fig_time = go.Figure()\n                \n                # Primary consolidation curve\n                fig_time.add_trace(go.Scatter(\n                    x=time_curve_data['time_years'],\n                    y=time_curve_data['settlement_primary_mm'],\n                    mode='lines',\n                    name='Primary Consolidation',\n                    line=dict(color='blue', width=2),\n                    hovertemplate='Time: %{x:.2f} years<br>Settlement: %{y:.1f} mm<extra></extra>'\n                ))\n                \n                # Total settlement (with secondary compression if included)\n                if time_curve_data['secondary_compression_included']:\n                    fig_time.add_trace(go.Scatter(\n                        x=time_curve_data['time_years'],\n                        y=time_curve_data['settlement_total_mm'],\n                        mode='lines',\n                        name='Total (Primary + Secondary)',\n                        line=dict(color='red', width=2, dash='dash'),\n                        hovertemplate='Time: %{x:.2f} years<br>Settlement: %{y:.1f} mm<extra></extra>'\n                    ))\n                \n                # Add horizontal line for immediate settlement\n                fig_time.add_hline(\n                    y=time_curve_data['immediate_settlement_mm'],\n                    line_dash=\"dot\",\n                    line_color=\"green\",\n                    annotation_text=f\"Immediate: {time_curve_data['immediate_settlement_mm']:.1f} mm\"\n                )\n                \n                fig_time.update_xaxes(\n                    title=\"Time (years)\",\n                    type='log',\n                    showgrid=True\n                )\n                fig_time.update_yaxes(\n                    title=\"Settlement (mm)\",\n                    showgrid=True\n                )\n                fig_time.update_layout(\n                    title=\"Settlement vs Time\",\n                    height=500,\n                    hovermode='x unified',\n                    legend=dict(\n                        yanchor=\"top\",\n                        y=0.99,\n                        xanchor=\"right\",\n                        x=0.99\n                    )\n                )\n                \n                st.plotly_chart(fig_time, use_container_width=True)\n                \n                # Settlement milestones\n                st.subheader(\"Settlement Milestones\")\n                \n                milestones_time = [0.1, 0.5, 1.0, 5.0, 10.0, 25.0, 50.0]\n                milestone_data = []\n                \n                for t in milestones_time:\n                    if t <= max_time:\n                        idx = min(range(len(time_curve_data['time_years'])), \n                                 key=lambda i: abs(time_curve_data['time_years'][i] - t))\n                        primary_settlement = time_curve_data['settlement_primary_mm'][idx]\n                        total_settlement = time_curve_data['settlement_total_mm'][idx]\n                        \n                        percent_complete = (primary_settlement / \n                                          (time_curve_data['immediate_settlement_mm'] + \n                                           time_curve_data['final_consolidation_mm'])) * 100 if time_curve_data['final_consolidation_mm'] > 0 else 100\n                        \n                        milestone_data.append({\n                            'Time (years)': t,\n                            'Primary (mm)': round(primary_settlement, 2),\n                            'Total (mm)': round(total_settlement, 2),\n                            '% Complete': round(percent_complete, 1)\n                        })\n                \n                milestone_df = pd.DataFrame(milestone_data)\n                st.dataframe(milestone_df, hide_index=True, use_container_width=True)\n                \n                # Consolidation time analysis\n                st.subheader(\"Consolidation Time by Layer\")\n                \n                col_time_a, col_time_b = st.columns(2)\n                \n                with col_time_a:\n                    target_degree = st.slider(\n                        \"Target Degree of Consolidation\",\n                        min_value=50,\n                        max_value=99,\n                        value=90,\n                        step=5,\n                        help=\"Percentage of consolidation to calculate time for\"\n                    ) / 100.0\n                \n                with col_time_b:\n                    if st.button(\"Calculate Layer Times\", key=\"layer_time_btn\"):\n                        # Get stored calculator and params\n                        calculator_stored = st.session_state.get('settlement_calculator', SettlementCalculator())\n                        cpt_name_stored = settlement_params_stored.get('cpt_name', selected_cpt_settle)\n                        params_stored = st.session_state.processed_cpts[cpt_name_stored]['parameters']\n                        \n                        layer_times = calculator_stored.calculate_consolidation_time(\n                            params_stored,\n                            target_degree=target_degree\n                        )\n                        st.session_state['layer_times'] = layer_times\n                \n                if 'layer_times' in st.session_state:\n                    layer_times = st.session_state['layer_times']\n                    layer_times_df = pd.DataFrame(layer_times['layer_times'])\n                    \n                    if len(layer_times_df) > 0:\n                        display_cols = ['layer_number', 'soil_type', 'thickness_m', 'time_days', 'time_years']\n                        available_cols = [col for col in display_cols if col in layer_times_df.columns]\n                        \n                        if available_cols:\n                            layer_times_display = layer_times_df[available_cols].copy()\n                            layer_times_display.columns = ['Layer', 'Soil Type', 'Thickness (m)', 'Time (days)', 'Time (years)']\n                            st.dataframe(layer_times_display.round(2), hide_index=True, use_container_width=True)\n                        else:\n                            st.dataframe(layer_times_df, hide_index=True, use_container_width=True)\n                        \n                        st.info(f\"ðŸ’¡ Time required for {int(target_degree*100)}% consolidation varies by layer based on drainage properties and permeability.\")\n            \n            st.markdown(\"---\")\n            \n            st.subheader(\"Export Settlement Results\")\n            exporter = ExportManager()\n            load_config = {\n                'load': settlement_params_stored.get('load', load_kN),\n                'width': settlement_params_stored.get('width', footing_width),\n                'length': settlement_params_stored.get('length', footing_length),\n                'depth': settlement_params_stored.get('depth', footing_depth)\n            }\n            \n            col_export1, col_export2 = st.columns(2)\n            \n            with col_export1:\n                excel_settle = exporter.export_settlement_results(\n                    settlement_results,\n                    params,\n                    load_config\n                )\n                st.download_button(\n                    label=\"ðŸ“¥ Download Settlement Results (Excel)\",\n                    data=excel_settle,\n                    file_name=f\"{selected_cpt_settle}_settlement.xlsx\",\n                    mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n                )\n            \n            with col_export2:\n                pdf_report = exporter.generate_pdf_report(\n                    selected_cpt_settle,\n                    st.session_state.processed_cpts[selected_cpt_settle]['summary'],\n                    st.session_state.processed_cpts[selected_cpt_settle]['layers'],\n                    params,\n                    settlement_results,\n                    load_config\n                )\n                st.download_button(\n                    label=\"ðŸ“„ Download Full Report (PDF)\",\n                    data=pdf_report,\n                    file_name=f\"{selected_cpt_settle}_report.pdf\",\n                    mime=\"application/pdf\"\n                )\n\nwith tab7:\n    st.header(\"3D Spatial Visualization\")\n    \n    if not st.session_state.processed_cpts:\n        st.info(\"ðŸ“Œ Please upload CPT data files in the 'Upload CPT Data' tab first.\")\n    elif len(st.session_state.processed_cpts) < 2:\n        st.warning(\"âš ï¸ 3D visualization requires at least 2 CPT datasets. Please upload more CPT files.\")\n    else:\n        st.markdown(\"\"\"\n        Visualize multiple CPT locations in 3D space to understand spatial soil variations.\n        Set the X and Y coordinates for each CPT location below.\n        \"\"\")\n        \n        st.subheader(\"ðŸ“ CPT Location Setup\")\n        \n        with st.expander(\"Set CPT Coordinates\", expanded=True):\n            coord_cols = st.columns(min(3, len(st.session_state.processed_cpts)))\n            \n            for idx, cpt_name in enumerate(st.session_state.processed_cpts.keys()):\n                col = coord_cols[idx % len(coord_cols)]\n                \n                with col:\n                    st.markdown(f\"**{cpt_name}**\")\n                    \n                    if cpt_name not in st.session_state.cpt_coordinates:\n                        st.session_state.cpt_coordinates[cpt_name] = {'x': idx * 10.0, 'y': 0.0}\n                    \n                    x_coord = st.number_input(\n                        f\"X (m)\",\n                        key=f\"x_{cpt_name}\",\n                        value=st.session_state.cpt_coordinates[cpt_name]['x'],\n                        step=1.0\n                    )\n                    y_coord = st.number_input(\n                        f\"Y (m)\",\n                        key=f\"y_{cpt_name}\",\n                        value=st.session_state.cpt_coordinates[cpt_name]['y'],\n                        step=1.0\n                    )\n                    \n                    st.session_state.cpt_coordinates[cpt_name] = {'x': x_coord, 'y': y_coord}\n        \n        st.markdown(\"---\")\n        \n        viz_type = st.selectbox(\n            \"Select Visualization Type\",\n            [\n                \"3D Soil Profile Scatter\",\n                \"3D Layer Surface Interpolation\",\n                \"2D Cross-Section\",\n                \"Plan View at Depth\"\n            ]\n        )\n        \n        visualizer = CPT3DVisualizer()\n        \n        cpt_locations = {}\n        for cpt_name, cpt_info in st.session_state.processed_cpts.items():\n            coords = st.session_state.cpt_coordinates.get(cpt_name, {'x': 0, 'y': 0})\n            cpt_locations[cpt_name] = {\n                'x': coords['x'],\n                'y': coords['y'],\n                'data': cpt_info['data'],\n                'layers': cpt_info['layers'].to_dict('records') if hasattr(cpt_info['layers'], 'to_dict') else cpt_info['layers']\n            }\n        \n        if viz_type == \"3D Soil Profile Scatter\":\n            st.subheader(\"3D Soil Profile Scatter Plot\")\n            st.markdown(\"Each CPT location is shown as a vertical scatter of soil types colored by classification.\")\n            \n            try:\n                fig = visualizer.create_3d_soil_profile(cpt_locations)\n                st.plotly_chart(fig, use_container_width=True)\n                \n                st.info(\"ðŸ’¡ Tip: Use your mouse to rotate, zoom, and pan the 3D view.\")\n            except Exception as e:\n                st.error(f\"Error creating 3D visualization: {str(e)}\")\n        \n        elif viz_type == \"3D Layer Surface Interpolation\":\n            st.subheader(\"3D Layer Surface Interpolation\")\n            st.markdown(\"Interpolated surfaces showing how soil layers vary across space.\")\n            \n            if len(cpt_locations) >= 3:\n                try:\n                    fig = visualizer.create_layer_surfaces(cpt_locations)\n                    st.plotly_chart(fig, use_container_width=True)\n                    \n                    st.info(\"ðŸ’¡ Tip: Surface interpolation requires at least 3 CPT locations for accurate results.\")\n                except Exception as e:\n                    st.error(f\"Error creating surface visualization: {str(e)}\")\n            else:\n                st.warning(\"âš ï¸ Surface interpolation requires at least 3 CPT locations. Currently showing vertical columns instead.\")\n                try:\n                    fig = visualizer.create_layer_surfaces(cpt_locations)\n                    st.plotly_chart(fig, use_container_width=True)\n                except Exception as e:\n                    st.error(f\"Error creating visualization: {str(e)}\")\n        \n        elif viz_type == \"2D Cross-Section\":\n            st.subheader(\"2D Cross-Section View\")\n            st.markdown(\"View a vertical slice through the soil profile between two points.\")\n            \n            col1, col2 = st.columns(2)\n            with col1:\n                st.markdown(\"**Start Point**\")\n                start_x = st.number_input(\"Start X (m)\", value=0.0, step=1.0, key=\"cross_start_x\")\n                start_y = st.number_input(\"Start Y (m)\", value=0.0, step=1.0, key=\"cross_start_y\")\n            \n            with col2:\n                st.markdown(\"**End Point**\")\n                end_x = st.number_input(\"End X (m)\", value=20.0, step=1.0, key=\"cross_end_x\")\n                end_y = st.number_input(\"End Y (m)\", value=0.0, step=1.0, key=\"cross_end_y\")\n            \n            try:\n                fig = visualizer.create_cross_section(\n                    cpt_locations,\n                    (start_x, start_y),\n                    (end_x, end_y)\n                )\n                st.plotly_chart(fig, use_container_width=True)\n                \n                st.info(\"ðŸ’¡ Tip: CPT locations within 1m of the cross-section line are marked with triangles.\")\n            except Exception as e:\n                st.error(f\"Error creating cross-section: {str(e)}\")\n        \n        elif viz_type == \"Plan View at Depth\":\n            st.subheader(\"Plan View at Specific Depth\")\n            st.markdown(\"Top-down view showing how soil types vary horizontally at a given depth.\")\n            \n            max_depth = max([cpt_info['data']['depth'].max() for cpt_info in st.session_state.processed_cpts.values()])\n            depth_slice = st.slider(\n                \"Select Depth (m)\",\n                min_value=0.0,\n                max_value=float(max_depth),\n                value=5.0,\n                step=0.5,\n                key=\"plan_depth\"\n            )\n            \n            try:\n                fig = visualizer.create_plan_view(cpt_locations, depth_slice)\n                st.plotly_chart(fig, use_container_width=True)\n                \n                st.info(\"ðŸ’¡ Tip: Use the slider to explore soil variations at different depths.\")\n            except Exception as e:\n                st.error(f\"Error creating plan view: {str(e)}\")\n        \n        st.markdown(\"---\")\n        st.subheader(\"ðŸ“Š Spatial Statistics\")\n        \n        col1, col2, col3 = st.columns(3)\n        with col1:\n            st.metric(\"Number of CPTs\", len(cpt_locations))\n        with col2:\n            x_coords = [loc['x'] for loc in cpt_locations.values()]\n            y_coords = [loc['y'] for loc in cpt_locations.values()]\n            area = (max(x_coords) - min(x_coords)) * (max(y_coords) - min(y_coords))\n            st.metric(\"Survey Area\", f\"{area:.1f} mÂ²\")\n        with col3:\n            avg_depth = np.mean([cpt_info['data']['depth'].max() for cpt_info in st.session_state.processed_cpts.values()])\n            st.metric(\"Average CPT Depth\", f\"{avg_depth:.1f} m\")\n\nst.sidebar.markdown(\"---\")\nst.sidebar.markdown(\"**ðŸ“š Based on:**\")\nst.sidebar.markdown(\"- Robertson (2009) CPT Classification\")\nst.sidebar.markdown(\"- Settle3 Correlations\")\nst.sidebar.markdown(\"- Terzaghi Consolidation Theory\")\n","size_bytes":60416},"visualization_3d.py":{"content":"\"\"\"\n3D Visualization module for spatial CPT analysis.\nDisplays multiple CPT locations with soil layer variations in 3D space.\n\"\"\"\n\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport pandas as pd\n\n\nclass CPT3DVisualizer:\n    \"\"\"\n    Create 3D visualizations of multiple CPT locations showing spatial soil variations.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize 3D visualizer with soil type color mapping.\"\"\"\n        self.soil_colors = {\n            'Sensitive, fine grained': '#8B4513',\n            'Clay - organic soil': '#654321',\n            'Clay': '#A0522D',\n            'Silt mixtures - clayey silt to silty clay': '#CD853F',\n            'Sand mixtures - silty sand to sandy silt': '#DEB887',\n            'Sands - clean sand to silty sand': '#F4A460',\n            'Dense sand to gravelly sand': '#FFD700',\n            'Very stiff sand to clayey sand': '#FFA500',\n            'Very stiff, over-consolidated or cemented': '#FF8C00'\n        }\n        \n        # Numeric mapping for interpolation\n        self.soil_type_numeric = {\n            'Sensitive, fine grained': 1,\n            'Clay - organic soil': 2,\n            'Clay': 3,\n            'Silt mixtures - clayey silt to silty clay': 4,\n            'Sand mixtures - silty sand to sandy silt': 5,\n            'Sands - clean sand to silty sand': 6,\n            'Dense sand to gravelly sand': 7,\n            'Very stiff sand to clayey sand': 8,\n            'Very stiff, over-consolidated or cemented': 9\n        }\n    \n    def create_3d_soil_profile(self, cpt_locations):\n        \"\"\"\n        Create 3D visualization of soil profiles at multiple CPT locations.\n        \n        Parameters:\n        -----------\n        cpt_locations : dict\n            Dictionary with CPT names as keys and values containing:\n            - 'x': X coordinate (m)\n            - 'y': Y coordinate (m)\n            - 'data': DataFrame with depth and soil_type columns\n            - 'layers': Layer information\n        \n        Returns:\n        --------\n        fig : plotly figure\n            3D visualization figure\n        \"\"\"\n        fig = go.Figure()\n        \n        # Add each CPT as a 3D scatter trace\n        for cpt_name, cpt_info in cpt_locations.items():\n            x_coord = cpt_info['x']\n            y_coord = cpt_info['y']\n            data = cpt_info['data']\n            \n            # Create arrays for 3D plotting\n            x_points = np.full(len(data), x_coord)\n            y_points = np.full(len(data), y_coord)\n            z_points = -data['depth'].values  # Negative for downward depth\n            \n            # Map soil types to colors\n            colors = [self.soil_colors.get(st, '#808080') for st in data['soil_type']]\n            \n            # Add scatter trace for this CPT\n            fig.add_trace(go.Scatter3d(\n                x=x_points,\n                y=y_points,\n                z=z_points,\n                mode='markers',\n                marker=dict(\n                    size=4,\n                    color=colors,\n                    line=dict(width=0.5, color='white')\n                ),\n                name=cpt_name,\n                text=[f\"Depth: {d:.2f}m<br>Soil: {st}\" \n                      for d, st in zip(data['depth'], data['soil_type'])],\n                hoverinfo='text'\n            ))\n        \n        # Update layout\n        fig.update_layout(\n            title='3D Spatial CPT Soil Profile Visualization',\n            scene=dict(\n                xaxis_title='X Coordinate (m)',\n                yaxis_title='Y Coordinate (m)',\n                zaxis_title='Depth (m)',\n                camera=dict(\n                    eye=dict(x=1.5, y=1.5, z=1.2)\n                )\n            ),\n            height=700,\n            showlegend=True\n        )\n        \n        return fig\n    \n    def create_layer_surfaces(self, cpt_locations, target_layers=None):\n        \"\"\"\n        Create 3D surface visualization showing interpolated layer boundaries.\n        \n        Parameters:\n        -----------\n        cpt_locations : dict\n            Dictionary with CPT data and coordinates\n        target_layers : list, optional\n            List of layer indices to visualize (default: all layers)\n        \n        Returns:\n        --------\n        fig : plotly figure\n            3D surface visualization\n        \"\"\"\n        fig = go.Figure()\n        \n        # Extract coordinates and layer data\n        x_coords = []\n        y_coords = []\n        layer_depths = {}\n        \n        for cpt_name, cpt_info in cpt_locations.items():\n            x_coords.append(cpt_info['x'])\n            y_coords.append(cpt_info['y'])\n            \n            # Get layer top/bottom depths\n            layers = cpt_info['layers']\n            for i, layer in enumerate(layers):\n                layer_key = f\"layer_{i}\"\n                if layer_key not in layer_depths:\n                    layer_depths[layer_key] = {\n                        'top': [],\n                        'bottom': [],\n                        'soil_type': layer['soil_type']\n                    }\n                layer_depths[layer_key]['top'].append(layer['depth_top'])\n                layer_depths[layer_key]['bottom'].append(layer['depth_bottom'])\n        \n        # Convert to arrays\n        x_coords = np.array(x_coords)\n        y_coords = np.array(y_coords)\n        \n        # Create grid for interpolation\n        if len(x_coords) >= 3:\n            xi = np.linspace(x_coords.min(), x_coords.max(), 50)\n            yi = np.linspace(y_coords.min(), y_coords.max(), 50)\n            xi, yi = np.meshgrid(xi, yi)\n            \n            # Interpolate layer surfaces\n            from scipy.interpolate import griddata\n            \n            for layer_key, layer_data in layer_depths.items():\n                if target_layers and layer_key not in target_layers:\n                    continue\n                \n                # Interpolate top surface\n                z_top = griddata(\n                    (x_coords, y_coords),\n                    -np.array(layer_data['top']),\n                    (xi, yi),\n                    method='linear'\n                )\n                \n                # Get color for this soil type\n                soil_type = layer_data['soil_type']\n                color = self.soil_colors.get(soil_type, '#808080')\n                \n                # Add surface\n                fig.add_trace(go.Surface(\n                    x=xi,\n                    y=yi,\n                    z=z_top,\n                    colorscale=[[0, color], [1, color]],\n                    showscale=False,\n                    name=f\"{layer_key}: {soil_type}\",\n                    opacity=0.7,\n                    hovertemplate='X: %{x:.1f}m<br>Y: %{y:.1f}m<br>Depth: %{z:.2f}m<extra></extra>'\n                ))\n        else:\n            # Not enough points for surface interpolation, add vertical columns\n            for i, (x, y) in enumerate(zip(x_coords, y_coords)):\n                cpt_name = list(cpt_locations.keys())[i]\n                layers = cpt_locations[cpt_name]['layers']\n                \n                for j, layer in enumerate(layers):\n                    z_vals = [-layer['depth_top'], -layer['depth_bottom']]\n                    color = self.soil_colors.get(layer['soil_type'], '#808080')\n                    \n                    fig.add_trace(go.Scatter3d(\n                        x=[x, x],\n                        y=[y, y],\n                        z=z_vals,\n                        mode='lines+markers',\n                        line=dict(color=color, width=8),\n                        marker=dict(size=6, color=color),\n                        name=f\"{cpt_name} - {layer['soil_type']}\",\n                        showlegend=(i == 0 and j == 0)\n                    ))\n        \n        fig.update_layout(\n            title='3D Layer Surface Interpolation',\n            scene=dict(\n                xaxis_title='X Coordinate (m)',\n                yaxis_title='Y Coordinate (m)',\n                zaxis_title='Depth (m)',\n                camera=dict(\n                    eye=dict(x=1.5, y=1.5, z=1.2)\n                )\n            ),\n            height=700,\n            showlegend=True\n        )\n        \n        return fig\n    \n    def create_cross_section(self, cpt_locations, start_point, end_point, num_points=100):\n        \"\"\"\n        Create a 2D cross-section view between two points.\n        \n        Parameters:\n        -----------\n        cpt_locations : dict\n            Dictionary with CPT data and coordinates\n        start_point : tuple\n            (x, y) coordinates of start point\n        end_point : tuple\n            (x, y) coordinates of end point\n        num_points : int\n            Number of interpolation points along the cross-section\n        \n        Returns:\n        --------\n        fig : plotly figure\n            Cross-section visualization\n        \"\"\"\n        from scipy.interpolate import griddata\n        \n        # Create line between points\n        x_line = np.linspace(start_point[0], end_point[0], num_points)\n        y_line = np.linspace(start_point[1], end_point[1], num_points)\n        distance = np.sqrt((x_line - start_point[0])**2 + (y_line - start_point[1])**2)\n        \n        # Collect all depth data from CPTs\n        x_coords = []\n        y_coords = []\n        depths = []\n        soil_types = []\n        \n        for cpt_name, cpt_info in cpt_locations.items():\n            data = cpt_info['data']\n            n_points = len(data)\n            x_coords.extend([cpt_info['x']] * n_points)\n            y_coords.extend([cpt_info['y']] * n_points)\n            depths.extend(data['depth'].values)\n            soil_types.extend(data['soil_type'].values)\n        \n        # Convert to numeric soil types for interpolation\n        soil_numeric = [self.soil_type_numeric.get(st, 5) for st in soil_types]\n        \n        # Create depth points for interpolation\n        max_depth = max(depths)\n        depth_points = np.linspace(0, max_depth, 100)\n        \n        # Create 2D grid for cross-section\n        distance_grid, depth_grid = np.meshgrid(distance, depth_points)\n        \n        # Interpolate soil types along the cross-section\n        soil_values = []\n        for d in depth_points:\n            depth_array = np.full(num_points, d)\n            points_3d = np.column_stack([x_line, y_line, depth_array])\n            \n            # Interpolate at these points\n            interpolated = griddata(\n                (x_coords, y_coords, depths),\n                soil_numeric,\n                (x_line, y_line, depth_array),\n                method='nearest'\n            )\n            soil_values.append(interpolated)\n        \n        soil_grid = np.array(soil_values)\n        \n        # Create figure\n        fig = go.Figure()\n        \n        fig.add_trace(go.Heatmap(\n            x=distance,\n            y=depth_points,\n            z=soil_grid,\n            colorscale='Earth',\n            showscale=True,\n            colorbar=dict(title='Soil Type'),\n            hovertemplate='Distance: %{x:.1f}m<br>Depth: %{y:.2f}m<extra></extra>'\n        ))\n        \n        # Mark CPT locations on the cross-section\n        for cpt_name, cpt_info in cpt_locations.items():\n            x_dist = np.sqrt((cpt_info['x'] - start_point[0])**2 + \n                           (cpt_info['y'] - start_point[1])**2)\n            \n            # Check if CPT is close to the line\n            if min(abs(distance - x_dist)) < 1.0:\n                fig.add_trace(go.Scatter(\n                    x=[x_dist],\n                    y=[0],\n                    mode='markers+text',\n                    marker=dict(size=12, color='red', symbol='triangle-down'),\n                    text=[cpt_name],\n                    textposition='top center',\n                    name=cpt_name,\n                    showlegend=False\n                ))\n        \n        fig.update_layout(\n            title=f'Cross-Section from ({start_point[0]:.1f}, {start_point[1]:.1f}) to ({end_point[0]:.1f}, {end_point[1]:.1f})',\n            xaxis_title='Distance along section (m)',\n            yaxis_title='Depth (m)',\n            yaxis_autorange='reversed',\n            height=600\n        )\n        \n        return fig\n    \n    def create_plan_view(self, cpt_locations, depth_slice):\n        \"\"\"\n        Create a plan view (top-down) showing soil types at a specific depth.\n        \n        Parameters:\n        -----------\n        cpt_locations : dict\n            Dictionary with CPT data and coordinates\n        depth_slice : float\n            Depth at which to show the plan view (m)\n        \n        Returns:\n        --------\n        fig : plotly figure\n            Plan view visualization\n        \"\"\"\n        from scipy.interpolate import griddata\n        \n        x_coords = []\n        y_coords = []\n        soil_at_depth = []\n        \n        for cpt_name, cpt_info in cpt_locations.items():\n            data = cpt_info['data']\n            \n            # Find soil type at the specified depth\n            idx = (data['depth'] - depth_slice).abs().idxmin()\n            soil_type = data.loc[idx, 'soil_type']\n            soil_numeric = self.soil_type_numeric.get(soil_type, 5)\n            \n            x_coords.append(cpt_info['x'])\n            y_coords.append(cpt_info['y'])\n            soil_at_depth.append(soil_numeric)\n        \n        x_coords = np.array(x_coords)\n        y_coords = np.array(y_coords)\n        soil_at_depth = np.array(soil_at_depth)\n        \n        # Create figure\n        fig = go.Figure()\n        \n        # Determine interpolation method based on number of points\n        num_points = len(x_coords)\n        \n        if num_points >= 4:\n            # Use cubic interpolation for 4+ points\n            xi = np.linspace(x_coords.min() - 5, x_coords.max() + 5, 100)\n            yi = np.linspace(y_coords.min() - 5, y_coords.max() + 5, 100)\n            xi, yi = np.meshgrid(xi, yi)\n            \n            zi = griddata(\n                (x_coords, y_coords),\n                soil_at_depth,\n                (xi, yi),\n                method='cubic'\n            )\n            \n            fig.add_trace(go.Contour(\n                x=xi[0],\n                y=yi[:, 0],\n                z=zi,\n                colorscale='Earth',\n                showscale=True,\n                colorbar=dict(title='Soil Type'),\n                contours=dict(\n                    showlabels=True,\n                    labelfont=dict(size=10, color='white')\n                )\n            ))\n        elif num_points == 3:\n            # Use linear interpolation for 3 points\n            xi = np.linspace(x_coords.min() - 5, x_coords.max() + 5, 100)\n            yi = np.linspace(y_coords.min() - 5, y_coords.max() + 5, 100)\n            xi, yi = np.meshgrid(xi, yi)\n            \n            zi = griddata(\n                (x_coords, y_coords),\n                soil_at_depth,\n                (xi, yi),\n                method='linear'\n            )\n            \n            fig.add_trace(go.Heatmap(\n                x=xi[0],\n                y=yi[:, 0],\n                z=zi,\n                colorscale='Earth',\n                showscale=True,\n                colorbar=dict(title='Soil Type')\n            ))\n        else:\n            # For 2 or fewer points, create voronoi-like visualization\n            # Expand the view around the points\n            if num_points == 2:\n                # Create a gradient between two points\n                x_range = max(abs(x_coords[1] - x_coords[0]), 10)\n                y_range = max(abs(y_coords[1] - y_coords[0]), 10)\n            else:\n                x_range = 10\n                y_range = 10\n            \n            xi = np.linspace(x_coords.min() - x_range/2, x_coords.max() + x_range/2, 100)\n            yi = np.linspace(y_coords.min() - y_range/2, y_coords.max() + y_range/2, 100)\n            xi, yi = np.meshgrid(xi, yi)\n            \n            # Use nearest neighbor interpolation for simple visualization\n            zi = griddata(\n                (x_coords, y_coords),\n                soil_at_depth,\n                (xi, yi),\n                method='nearest'\n            )\n            \n            fig.add_trace(go.Heatmap(\n                x=xi[0],\n                y=yi[:, 0],\n                z=zi,\n                colorscale='Earth',\n                showscale=True,\n                colorbar=dict(title='Soil Type')\n            ))\n        \n        # Add CPT location markers\n        cpt_names = list(cpt_locations.keys())\n        \n        # Create color for markers based on soil type\n        marker_colors = [self.soil_colors.get(\n            [k for k, v in self.soil_type_numeric.items() if v == st][0] if st in self.soil_type_numeric.values() else 'Unknown',\n            '#808080'\n        ) for st in soil_at_depth]\n        \n        fig.add_trace(go.Scatter(\n            x=x_coords,\n            y=y_coords,\n            mode='markers+text',\n            marker=dict(\n                size=15,\n                color=marker_colors,\n                symbol='circle',\n                line=dict(width=2, color='white')\n            ),\n            text=cpt_names,\n            textposition='top center',\n            name='CPT Locations',\n            hovertemplate='<b>%{text}</b><br>X: %{x:.1f}m<br>Y: %{y:.1f}m<extra></extra>'\n        ))\n        \n        fig.update_layout(\n            title=f'Plan View at Depth = {depth_slice:.2f}m',\n            xaxis_title='X Coordinate (m)',\n            yaxis_title='Y Coordinate (m)',\n            height=600,\n            width=700\n        )\n        \n        return fig\n","size_bytes":17533},".streamlit/config.toml":{"content":"[server]\nheadless = true\naddress = \"0.0.0.0\"\nport = 5000\nmaxUploadSize = 400\nenableXsrfProtection = false\nenableCORS = false","size_bytes":124},"test_cpt_files.py":{"content":"\"\"\"\nTest script to process user's CPT text files and verify the application works\n\"\"\"\nimport pandas as pd\nfrom io import StringIO\nfrom cpt_processor import CPTProcessor\nfrom soil_classification import SoilLayering\nfrom correlations import CPTCorrelations\nfrom settlement_calc import SettlementCalculator\n\n# Sample data from user's file \"21-544_Settle_3D_1761927830944.txt\"\n# Tab-delimited, no headers, 4 columns: depth, qc, fs, u2\nsample_data = \"\"\"0.082  0.01    0       0\n0.164   0.01    0       0\n0.246   0.01    0       0\n0.328   0.01    0       0\n0.41    0.01    0       0\n0.492   0.01    0       0\n0.574   0.01    0       0\n0.656   0.01    0       0\n0.738   0.01    0       0\n0.82    127.73  0.498   6.461\n0.902   168.15  0.568   7.543\n0.984   159.32  0.626   2.514\n1.066   140.16  0.728   0.658\n1.148   125.04  0.703   0.138\n1.23    115.38  0.654   0.788\n1.312   106.28  0.661   -0.277\n1.394   98.65   0.982   0.571\n1.476   89.17   0.831   -0.32\n1.558   85.22   0.869   0.229\n1.64    83.34   0.808   -1.207\n1.722   69.25   0.835   2.467\n1.804   64.23   0.743   0.29\n1.886   55.76   0.623   0.299\n1.968   52.27   0.442   -0.004\n2.051   42.02   0.411   -0.164\n2.133   36.55   0.442   -0.087\n2.215   33.71   0.737   -0.061\n2.297   30.38   0.536   -0.091\n2.379   30.97   0.504   0.108\n2.461   30.89   0.511   0.515\n2.543   27.5    0.536   2.778\n2.625   32.07   0.625   3.272\n2.707   35.76   0.539   1.216\n2.789   38.2    0.617   -1.644\n2.871   37.91   0.78    -3.735\n2.953   36.25   0.86    -5.678\n3.035   31.86   0.586   -6.284\n3.117   28.09   0.534   -6.31\n3.199   28.87   0.512   -5.535\n3.281   32.53   0.503   -3.994\"\"\"\n\ndef test_file_processing():\n    print(\"=\" * 70)\n    print(\"TESTING CPT FILE PROCESSING\")\n    print(\"=\" * 70)\n    \n    # Create a mock file object\n    class MockFile:\n        def __init__(self, content):\n            self.content = content\n        \n        def read(self):\n            return self.content.encode('utf-8')\n    \n    mock_file = MockFile(sample_data)\n    \n    # Test 1: Parse the text file\n    print(\"\\n1. Testing Text File Parser (no headers, tab-delimited)...\")\n    processor = CPTProcessor()\n    \n    try:\n        df = processor.parse_text(mock_file)\n        print(f\"   âœ“ Successfully parsed {len(df)} rows\")\n        print(f\"   âœ“ Columns: {list(df.columns)}\")\n        print(f\"   âœ“ Depth range: {df['depth'].min():.2f}m to {df['depth'].max():.2f}m\")\n        print(f\"   âœ“ qc range: {df['qc'].min():.2f} to {df['qc'].max():.2f} kPa\")\n        print(f\"\\n   Sample data (first 5 rows):\")\n        print(df.head().to_string(index=False))\n    except Exception as e:\n        print(f\"   âœ— ERROR: {e}\")\n        return False\n    \n    # Test 2: Calculate normalized parameters\n    print(\"\\n2. Testing CPT Data Normalization...\")\n    try:\n        soil_unit_weight = 18.0\n        water_table_depth = 2.0\n        net_area_ratio = 0.8\n        \n        processed = processor.calculate_normalized_parameters(\n            df, soil_unit_weight, water_table_depth, net_area_ratio\n        )\n        print(f\"   âœ“ Successfully calculated normalized parameters\")\n        print(f\"   âœ“ Added parameters: Qt, Fr, Bq, Ic\")\n        print(f\"   âœ“ Ic range: {processed['Ic'].min():.2f} to {processed['Ic'].max():.2f}\")\n    except Exception as e:\n        print(f\"   âœ— ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n    \n    # Test 3: Apply soil classification\n    print(\"\\n3. Applying Soil Classification...\")\n    try:\n        # Add soil_type based on Ic (Robertson 2009 classification)\n        processed['soil_type'] = processed['Ic'].apply(processor.identify_soil_type)\n        \n        soil_types = processed['soil_type'].value_counts()\n        print(f\"   âœ“ Soil types identified in data:\")\n        for soil, count in soil_types.items():\n            print(f\"      - {soil}: {count} points\")\n    except Exception as e:\n        print(f\"   âœ— ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n    \n    # Test 4: Layer identification\n    print(\"\\n4. Testing Layer Identification...\")\n    try:\n        layering = SoilLayering(min_layer_thickness=0.5)\n        layers = layering.identify_layers(processed)\n        print(f\"   âœ“ Successfully identified {len(layers)} layers\")\n        print(f\"\\n   Layer Summary:\")\n        for _, layer in layers.iterrows():\n            print(f\"      Layer {layer['layer_number']}: {layer['soil_type']}\")\n            print(f\"         Depth: {layer['top_depth']:.2f}m to {layer['bottom_depth']:.2f}m ({layer['thickness']:.2f}m)\")\n    except Exception as e:\n        print(f\"   âœ— ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n    \n    # Test 5: Calculate parameters\n    print(\"\\n5. Testing Parameter Calculations...\")\n    try:\n        correlator = CPTCorrelations()\n        parameters = correlator.calculate_all_parameters(processed, layers, soil_unit_weight)\n        print(f\"   âœ“ Successfully calculated parameters for {len(parameters)} layers\")\n        print(f\"\\n   Parameter Summary (first 3 layers):\")\n        cols = ['layer_number', 'youngs_modulus', 'constrained_modulus', 'compression_index', 'OCR']\n        if len(parameters) > 0:\n            print(parameters[cols].head(3).to_string(index=False))\n        else:\n            print(\"      No parameters calculated (may need more layers)\")\n    except Exception as e:\n        print(f\"   âœ— ERROR: {e}\")\n        import traceback\n        traceback.print_exc()\n        return False\n    \n    # Test 6: Settlement calculation\n    print(\"\\n6. Testing Settlement Calculation...\")\n    try:\n        calc = SettlementCalculator()\n        \n        # Test footing parameters\n        footing_width = 2.0\n        footing_length = 2.0\n        footing_depth = 1.0\n        applied_stress = 100.0\n        \n        settlement = calc.calculate_settlement(\n            parameters, footing_width, footing_length, \n            footing_depth, applied_stress\n        )\n        \n        print(f\"   âœ“ Successfully calculated settlement\")\n        print(f\"   âœ“ Total Immediate Settlement: {settlement['total_immediate']:.2f} mm\")\n        print(f\"   âœ“ Total Consolidation Settlement: {settlement['total_consolidation']:.2f} mm\")\n        print(f\"   âœ“ Total Settlement: {settlement['total']:.2f} mm\")\n        \n        if 'layer_breakdown' in settlement:\n            print(f\"\\n   Settlement by Layer (first 3 layers):\")\n            breakdown = settlement['layer_breakdown'].head(3)\n            cols = ['layer_number', 'immediate_settlement', 'consolidation_settlement', 'total_settlement']\n            print(breakdown[cols].to_string(index=False))\n    except Exception as e:\n        print(f\"   âœ— ERROR: {e}\")\n        return False\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"âœ“ ALL TESTS PASSED!\")\n    print(\"=\" * 70)\n    return True\n\nif __name__ == \"__main__\":\n    success = test_file_processing()\n    if not success:\n        print(\"\\nâš  Some tests failed. Please check the errors above.\")\n        exit(1)\n","size_bytes":7018},"soil_database.py":{"content":"import pandas as pd\nimport numpy as np\nfrom typing import Dict, List, Tuple\n\nclass SoilPropertyDatabase:\n    \"\"\"\n    Reference database for typical soil properties based on soil classification.\n    Values based on geotechnical engineering literature and standards.\n    \"\"\"\n    \n    def __init__(self):\n        # Database of typical soil properties by soil behavior type\n        self.soil_properties = {\n            'Sensitive fine grained': {\n                'Ic_range': (3.6, 4.0),\n                'youngs_modulus_range': (500, 2000),  # kPa\n                'compression_index_range': (0.3, 0.6),\n                'recompression_index_range': (0.03, 0.08),\n                'OCR_range': (1.0, 2.0),\n                'friction_angle_range': (0, 0),  # degrees\n                'undrained_shear_strength_range': (10, 30),  # kPa\n                'permeability_range': (1e-10, 1e-8),  # m/s\n                'unit_weight_range': (14, 18),  # kN/mÂ³\n                'description': 'Very soft to soft clay, highly compressible'\n            },\n            'Organic soil': {\n                'Ic_range': (3.6, 4.0),\n                'youngs_modulus_range': (300, 1500),\n                'compression_index_range': (0.4, 0.8),\n                'recompression_index_range': (0.04, 0.10),\n                'OCR_range': (1.0, 1.5),\n                'friction_angle_range': (0, 0),\n                'undrained_shear_strength_range': (5, 20),\n                'permeability_range': (1e-9, 1e-7),\n                'unit_weight_range': (12, 16),\n                'description': 'Organic clay and peat, very compressible'\n            },\n            'Clay': {\n                'Ic_range': (2.95, 3.6),\n                'youngs_modulus_range': (2000, 8000),\n                'compression_index_range': (0.2, 0.5),\n                'recompression_index_range': (0.02, 0.06),\n                'OCR_range': (1.0, 4.0),\n                'friction_angle_range': (20, 28),\n                'undrained_shear_strength_range': (20, 80),\n                'permeability_range': (1e-10, 1e-8),\n                'unit_weight_range': (16, 20),\n                'description': 'Soft to stiff clay, moderate compressibility'\n            },\n            'Silty clay to clay': {\n                'Ic_range': (2.95, 3.6),\n                'youngs_modulus_range': (3000, 10000),\n                'compression_index_range': (0.15, 0.35),\n                'recompression_index_range': (0.015, 0.04),\n                'OCR_range': (1.0, 6.0),\n                'friction_angle_range': (22, 30),\n                'undrained_shear_strength_range': (30, 100),\n                'permeability_range': (1e-9, 1e-7),\n                'unit_weight_range': (17, 21),\n                'description': 'Medium stiff clay with silt content'\n            },\n            'Clayey silt to silty clay': {\n                'Ic_range': (2.6, 2.95),\n                'youngs_modulus_range': (5000, 15000),\n                'compression_index_range': (0.1, 0.25),\n                'recompression_index_range': (0.01, 0.03),\n                'OCR_range': (1.0, 8.0),\n                'friction_angle_range': (24, 32),\n                'undrained_shear_strength_range': (40, 120),\n                'permeability_range': (1e-8, 1e-6),\n                'unit_weight_range': (18, 21),\n                'description': 'Stiff silty clay, low to medium compressibility'\n            },\n            'Sandy silt to clayey silt': {\n                'Ic_range': (2.05, 2.6),\n                'youngs_modulus_range': (10000, 30000),\n                'compression_index_range': (0.05, 0.15),\n                'recompression_index_range': (0.005, 0.02),\n                'OCR_range': (1.0, 10.0),\n                'friction_angle_range': (28, 34),\n                'undrained_shear_strength_range': (0, 0),\n                'permeability_range': (1e-7, 1e-5),\n                'unit_weight_range': (18, 22),\n                'description': 'Dense silt mixtures, low compressibility'\n            },\n            'Silty sand to sandy silt': {\n                'Ic_range': (1.8, 2.05),\n                'youngs_modulus_range': (15000, 40000),\n                'compression_index_range': (0.02, 0.08),\n                'recompression_index_range': (0.002, 0.01),\n                'OCR_range': (1.0, 15.0),\n                'friction_angle_range': (30, 36),\n                'undrained_shear_strength_range': (0, 0),\n                'permeability_range': (1e-6, 1e-4),\n                'unit_weight_range': (19, 22),\n                'description': 'Medium to dense silty sand'\n            },\n            'Sand to silty sand': {\n                'Ic_range': (1.31, 1.8),\n                'youngs_modulus_range': (20000, 60000),\n                'compression_index_range': (0.01, 0.05),\n                'recompression_index_range': (0.001, 0.005),\n                'OCR_range': (1.0, 20.0),\n                'friction_angle_range': (32, 40),\n                'undrained_shear_strength_range': (0, 0),\n                'permeability_range': (1e-5, 1e-3),\n                'unit_weight_range': (19, 23),\n                'description': 'Dense sand, very low compressibility'\n            },\n            'Sand': {\n                'Ic_range': (0.0, 1.31),\n                'youngs_modulus_range': (30000, 100000),\n                'compression_index_range': (0.005, 0.03),\n                'recompression_index_range': (0.0005, 0.003),\n                'OCR_range': (1.0, 30.0),\n                'friction_angle_range': (34, 42),\n                'undrained_shear_strength_range': (0, 0),\n                'permeability_range': (1e-4, 1e-2),\n                'unit_weight_range': (20, 24),\n                'description': 'Very dense clean sand, negligible compressibility'\n            }\n        }\n    \n    def get_typical_properties(self, soil_type: str) -> Dict:\n        \"\"\"Get typical property ranges for a soil type.\"\"\"\n        return self.soil_properties.get(soil_type, None)\n    \n    def get_soil_type_from_ic(self, Ic: float) -> str:\n        \"\"\"Determine soil type from Soil Behavior Type Index (Ic).\"\"\"\n        for soil_type, props in self.soil_properties.items():\n            ic_min, ic_max = props['Ic_range']\n            if ic_min <= Ic <= ic_max:\n                return soil_type\n        return \"Unknown\"\n    \n    def validate_parameter(self, soil_type: str, parameter_name: str, value: float) -> Tuple[bool, str]:\n        \"\"\"\n        Validate if a calculated parameter falls within typical ranges.\n        \n        Returns:\n        - (True, \"within range\") if value is typical\n        - (False, warning_message) if value is outside typical range\n        \"\"\"\n        props = self.get_typical_properties(soil_type)\n        if props is None:\n            return (True, \"Unknown soil type\")\n        \n        # Map parameter names to database keys\n        param_map = {\n            'youngs_modulus': 'youngs_modulus_range',\n            'E': 'youngs_modulus_range',\n            'compression_index': 'compression_index_range',\n            'Cc': 'compression_index_range',\n            'recompression_index': 'recompression_index_range',\n            'Cr': 'recompression_index_range',\n            'OCR': 'OCR_range',\n            'friction_angle': 'friction_angle_range',\n            'phi': 'friction_angle_range',\n            'undrained_shear_strength': 'undrained_shear_strength_range',\n            'cu': 'undrained_shear_strength_range',\n            'permeability': 'permeability_range',\n            'k': 'permeability_range',\n            'unit_weight': 'unit_weight_range',\n            'gamma': 'unit_weight_range'\n        }\n        \n        range_key = param_map.get(parameter_name)\n        if range_key is None or range_key not in props:\n            return (True, f\"Parameter '{parameter_name}' not in database\")\n        \n        min_val, max_val = props[range_key]\n        \n        # Allow some tolerance for boundary cases\n        tolerance = 0.2  # 20% tolerance\n        extended_min = min_val * (1 - tolerance)\n        extended_max = max_val * (1 + tolerance)\n        \n        if min_val <= value <= max_val:\n            return (True, \"Within typical range\")\n        elif extended_min <= value <= extended_max:\n            return (False, f\"âš ï¸ Near boundary: typical range is {min_val:.2e} to {max_val:.2e}\")\n        else:\n            return (False, f\"âš ï¸ Outside typical range: expected {min_val:.2e} to {max_val:.2e}, got {value:.2e}\")\n    \n    def get_database_summary(self) -> pd.DataFrame:\n        \"\"\"Get a summary dataframe of all soil types and their properties.\"\"\"\n        data = []\n        for soil_type, props in self.soil_properties.items():\n            data.append({\n                'Soil Type': soil_type,\n                'Ic Range': f\"{props['Ic_range'][0]:.2f} - {props['Ic_range'][1]:.2f}\",\n                'E (kPa)': f\"{props['youngs_modulus_range'][0]:.0f} - {props['youngs_modulus_range'][1]:.0f}\",\n                'Cc': f\"{props['compression_index_range'][0]:.3f} - {props['compression_index_range'][1]:.3f}\",\n                'Ï† (Â°)': f\"{props['friction_angle_range'][0]:.0f} - {props['friction_angle_range'][1]:.0f}\" if props['friction_angle_range'][0] > 0 else \"N/A\",\n                'Description': props['description']\n            })\n        \n        return pd.DataFrame(data)\n    \n    def compare_layer_properties(self, layer_params: pd.DataFrame) -> List[Dict]:\n        \"\"\"\n        Compare calculated layer properties against typical database ranges.\n        \n        Returns list of warnings for parameters outside typical ranges.\n        \"\"\"\n        warnings = []\n        \n        for idx, layer in layer_params.iterrows():\n            soil_type = layer.get('soil_type', 'Unknown')\n            layer_num = layer.get('layer_number', idx + 1)\n            \n            # Check each parameter\n            parameters_to_check = [\n                ('youngs_modulus', 'E'),\n                ('compression_index', 'Cc'),\n                ('recompression_index', 'Cr'),\n                ('OCR', 'OCR'),\n                ('permeability', 'k')\n            ]\n            \n            if 'friction_angle' in layer and layer['friction_angle'] > 0:\n                parameters_to_check.append(('friction_angle', 'Ï†'))\n            if 'undrained_shear_strength' in layer and layer['undrained_shear_strength'] > 0:\n                parameters_to_check.append(('undrained_shear_strength', 'cu'))\n            \n            for param_key, param_display in parameters_to_check:\n                if param_key in layer:\n                    value = layer[param_key]\n                    is_valid, message = self.validate_parameter(soil_type, param_key, value)\n                    \n                    if not is_valid:\n                        warnings.append({\n                            'layer_number': layer_num,\n                            'soil_type': soil_type,\n                            'parameter': param_display,\n                            'value': value,\n                            'message': message\n                        })\n        \n        return warnings\n","size_bytes":11011}},"version":2}